model,developer,release_date,parameters,parameter_source,training_flop,confidence,confidence_explanation,estimation_method,alternative_methods,threshold_classification,status,reasoning,sources,verified,last_updated,notes
claude_opus_4,Anthropic,,175000000000.0,known_specification:claude_opus,1.50e+26,low,Speculative research estimate,epoch_estimate,Scaling Laws: 8.40e+24 (Medium); Benchmark Based: 4.67e+25 (Medium),high_confidence_above_1e25,uncertain,https://epoch.ai/data-insights/models-over-1e25-flop: Speculative estimate for next-gen Claude,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.102414,
claude_opus_4_thinking_16k,Anthropic,,175000000000.0,known_specification:claude_opus,1.50e+26,low,Speculative research estimate,epoch_estimate,Scaling Laws: 8.40e+24 (Medium); Benchmark Based: 4.58e+25 (Medium),high_confidence_above_1e25,uncertain,https://epoch.ai/data-insights/models-over-1e25-flop: Speculative estimate for next-gen Claude,LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T19:50:21.102062,
gpt_4.5_preview,OpenAI,,1760000000000.0,known_specification:gpt_4,6.40e+25,low,Speculative research estimate,epoch_estimate,Scaling Laws: 1.37e+26 (Medium); Benchmark Based: 5.01e+25 (Medium),high_confidence_above_1e25,uncertain,https://epoch.ai/data-insights/models-over-1e25-flop: Low-precision estimate for GPT-4.5,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.101799,
gemini_2.0_flash,Google,,500000000000.0,,6.000000000000001e+25,low,,scaling_laws,,high_confidence_above_1e25,uncertain,"Known model specification: Chinchilla scaling law: 6 × 500,000,000,000 params × 20,000,000,000,000 tokens = 6.00e+25 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),y,2025-07-31T18:56:49.505562,
gemini_2.0_flash_001,Google,,500000000000.0,known_specification:gemini_2.0,6.00e+25,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 4.07e+25 (Medium),high_confidence_above_1e25,uncertain,"Known model specification 'gemini_2.0': Chinchilla scaling law: 6 × 500,000,000,000 params × 20,000,000,000,000 tokens = 6.00e+25 FLOP",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T19:50:21.104722,
gemini_2.0_flash_lite,Google,,500000000000.0,known_specification:gemini_2.0,6.00e+25,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 4.18e+25 (Medium),high_confidence_above_1e25,uncertain,"Known model specification 'gemini_2.0': Chinchilla scaling law: 6 × 500,000,000,000 params × 20,000,000,000,000 tokens = 6.00e+25 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.105248,
gemini_2.0_pro,Google,,500000000000.0,known_specification:gemini_2.0,6.00e+25,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 4.79e+25 (Medium),high_confidence_above_1e25,uncertain,"Known model specification 'gemini_2.0': Chinchilla scaling law: 6 × 500,000,000,000 params × 20,000,000,000,000 tokens = 6.00e+25 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.125808,
gemini_2.5_flash,Google,,500000000000.0,known_specification:gemini_2,6.00e+25,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 5.01e+25 (Medium),high_confidence_above_1e25,uncertain,"Known model specification 'gemini_2': Chinchilla scaling law: 6 × 500,000,000,000 params × 20,000,000,000,000 tokens = 6.00e+25 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.102659,
gemini_2.5_pro,Google,,500000000000.0,known_specification:gemini_2,6.00e+25,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 5.61e+25 (Medium),high_confidence_above_1e25,uncertain,"Known model specification 'gemini_2': Chinchilla scaling law: 6 × 500,000,000,000 params × 20,000,000,000,000 tokens = 6.00e+25 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.101269,
deepseek_coder,DeepSeek,,671000000000.0,known_specification:deepseek,5.96e+25,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 3.26e+25 (Medium),high_confidence_above_1e25,likely_above_1e25,"Known model specification 'deepseek': Chinchilla scaling law: 6 × 671,000,000,000 params × 14,800,000,000,000 tokens = 5.96e+25 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.112325,
deepseek_llm_67b,DeepSeek,,671000000000.0,known_specification:deepseek,5.96e+25,medium,Known parameters with estimated training tokens,scaling_laws,Scaling Laws: 4.04e+23 (Low); Benchmark Based: 2.40e+25 (Medium),high_confidence_above_1e25,likely_above_1e25,"Known model specification 'deepseek': Chinchilla scaling law: 6 × 671,000,000,000 params × 14,800,000,000,000 tokens = 5.96e+25 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.116638,
deepseek_v2_api,DeepSeek,,671000000000.0,known_specification:deepseek,5.96e+25,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 3.44e+25 (Medium),high_confidence_above_1e25,likely_above_1e25,"Known model specification 'deepseek': Chinchilla scaling law: 6 × 671,000,000,000 params × 14,800,000,000,000 tokens = 5.96e+25 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.130737,
grok_4,xAI,,,,5.24e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,high_confidence_above_1e25,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 5.28e+25 (Low); coding_score: 5.20e+25 (Low) → weighted average: 5.24e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.101924,
o3,OpenAI,,,,5.22e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,high_confidence_above_1e25,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 5.20e+25 (Low); coding_score: 5.23e+25 (Low) → weighted average: 5.22e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.101479,
grok_3,xAI,,,,5.16e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,high_confidence_above_1e25,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 5.16e+25 (Low); coding_score: 5.17e+25 (Low) → weighted average: 5.16e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.102531,
hunyuan_turbos,Tencent,,,,4.65e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 4.65e+25 (Medium); coding_score: 4.64e+25 (Medium) → weighted average: 4.65e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.103892,
mistral_medium_3,Mistral,,,,4.61e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 4.59e+25 (Medium); coding_score: 4.63e+25 (Medium) → weighted average: 4.61e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.128545,
o4_mini,OpenAI,,,,4.56e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 4.50e+25 (Medium); coding_score: 4.61e+25 (Medium) → weighted average: 4.56e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.103121,
kimi_k2_preview,Moonshot,,,,4.55e+25,medium,,benchmark_based,,not_sure,likely_above_1e25,"Benchmark-based (openlm_arena_elo): Benchmark-based estimation: ELO 1380.0 vs reference llama_405b (ELO 1300, 3.80e+25 FLOP) with power law scaling α=3.0 = 4.55e+25 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),y,2025-08-01T15:52:05.757110,Manual review - confirmed above 1e25 FLOP. Reason: Example reasoning
o1,OpenAI,,,,4.55e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 4.55e+25 (Medium); coding_score: 4.54e+25 (Medium) → weighted average: 4.55e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.102869,
qwen2.5_max,Alibaba,,,,4.53e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 4.56e+25 (Medium); coding_score: 4.49e+25 (Medium) → weighted average: 4.53e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.104425,
claude_3_7_sonnet,Anthropic,,,,4.47e+25,medium,,benchmark_based,,not_sure,likely_above_1e25,"Benchmark-based (lmarena_score): Benchmark-based estimation: ELO 1372.0 vs reference llama_405b (ELO 1300, 3.80e+25 FLOP) with power law scaling α=3.0 = 4.47e+25 FLOP",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),y,2025-08-01T17:43:00.800819,Manual review - confirmed above 1e25 FLOP. Reason: This is a big model... pretty sure it's over 1e25 flop
claude_sonnet_4,Anthropic,,,,4.46e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 4.30e+25 (Medium); coding_score: 4.63e+25 (Medium) → weighted average: 4.46e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.103368,
minimax_m1,MiniMax,,,,4.45e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 4.45e+25 (Medium); coding_score: 4.45e+25 (Medium) → weighted average: 4.45e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.104023,
claude_sonnet_4_thinking_32k,Anthropic,,,,4.38e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,"Benchmark-based (lmarena_score): 1400.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 4.38e+25 FLOP",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T19:50:21.102757,
mistral_small,Mistral,,,,4.32e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 4.25e+25 (Medium); coding_score: 4.38e+25 (Medium) → weighted average: 4.32e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.105491,
qwen3_coder_480b,Alibaba,,480000000000.0,known_specification:qwen3_coder_480b,4.32e+25,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 4.59e+25 (Medium),not_sure,likely_above_1e25,"Known model specification 'qwen3_coder_480b': Chinchilla scaling law: 6 × 480,000,000,000 params × 15,000,000,000,000 tokens = 4.32e+25 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.103254,
claude_3_7_sonnet_thinking_32k,Anthropic,,,,4.26e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,"Benchmark-based (lmarena_score): 1387.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 4.26e+25 FLOP",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T19:50:21.103500,
o1_mini,OpenAI,,,,4.26e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 4.10e+25 (Medium); coding_score: 4.42e+25 (Medium) → weighted average: 4.26e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.106471,
o1_preview,OpenAI,,,,4.24e+25,low,Distant benchmark interpolation or single source,benchmark_based,,not_sure,uncertain,"Benchmark-based (lmarena_score): 1385.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 4.24e+25 FLOP",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T19:50:21.103619,
o3_mini,OpenAI,,,,4.23e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 4.09e+25 (Medium); coding_score: 4.36e+25 (Medium) → weighted average: 4.23e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.104835,
command_a,Cohere,,,,4.14e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 4.17e+25 (Medium); coding_score: 4.12e+25 (Medium) → weighted average: 4.14e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.128865,
amazon_nova_chat_05_14,Amazon,,,,4.12e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 4.13e+25 (Medium); coding_score: 4.12e+25 (Medium) → weighted average: 4.12e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.129042,
hunyuan_turbo,Tencent,,,,4.09e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 4.05e+25 (Medium); coding_score: 4.12e+25 (Medium) → weighted average: 4.09e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.105958,
claude_3.7_sonnet,Anthropic,,,,4.07e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.94e+25 (Medium); coding_score: 4.19e+25 (Medium) → weighted average: 4.07e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.129204,
step_2,StepFun,,,,4.02e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 4.12e+25 (Medium); coding_score: 3.92e+25 (Medium) → weighted average: 4.02e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.106360,
yi_lightning,01 AI,,,,3.97e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.95e+25 (Medium); coding_score: 4.00e+25 (Medium) → weighted average: 3.97e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.107102,
command_a_03,Cohere,,,,3.90e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,"Benchmark-based (lmarena_score): 1347.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 3.90e+25 FLOP",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T19:50:21.105581,
hunyuan_large,Tencent,,,,3.88e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.84e+25 (Medium); coding_score: 3.91e+25 (Medium) → weighted average: 3.88e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.107184,
claude_3_5_sonnet,Anthropic,,,,3.84e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,"Benchmark-based (lmarena_score): 1340.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 3.84e+25 FLOP",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T19:50:21.104614,
glm_4_plus,Zhipu,,,,3.84e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.85e+25 (Medium); coding_score: 3.82e+25 (Medium) → weighted average: 3.84e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.105850,
chatgpt_4o,OpenAI,,1760000000000.0,known_specification:gpt_4,3.80e+25,medium,Reliable research estimate from industry analysis,epoch_estimate,Scaling Laws: 1.37e+26 (Medium); Benchmark Based: 5.17e+25 (Medium),not_sure,likely_above_1e25,https://epoch.ai/data-insights/models-over-1e25-flop: Low-precision estimate from OpenAI patterns,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.101620,
gpt_4o,OpenAI,,1760000000000.0,known_specification:gpt_4,3.80e+25,medium,Reliable research estimate from industry analysis,epoch_estimate,Scaling Laws: 1.37e+26 (Medium); Benchmark Based: 3.91e+25 (Medium),not_sure,likely_above_1e25,https://epoch.ai/data-insights/models-over-1e25-flop: Low-precision estimate from OpenAI patterns,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.106172,
gpt_4o_mini,OpenAI,,1760000000000.0,known_specification:gpt_4,3.80e+25,medium,Reliable research estimate from industry analysis,epoch_estimate,Scaling Laws: 1.37e+26 (Medium); Benchmark Based: 3.82e+25 (Medium),not_sure,likely_above_1e25,https://epoch.ai/data-insights/models-over-1e25-flop: Low-precision estimate from OpenAI patterns,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.108236,
llama_3.1_405b_instruct_bf16,Meta,,405000000000.0,known_specification:llama_3.1_405b,3.80e+25,high,Official disclosure or high-precision research estimate,epoch_estimate,Scaling Laws: 3.65e+25 (High); Benchmark Based: 3.80e+25 (Medium),not_sure,confirmed_above_1e25,https://epoch.ai/data-insights/models-over-1e25-flop: High-precision estimate from Meta disclosure,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.106580,
llama_3.1_405b_instruct_fp8,Meta,,405000000000.0,known_specification:llama_3.1_405b,3.80e+25,high,Official disclosure or high-precision research estimate,epoch_estimate,Scaling Laws: 3.65e+25 (High); Benchmark Based: 3.76e+25 (Medium),not_sure,confirmed_above_1e25,https://epoch.ai/data-insights/models-over-1e25-flop: High-precision estimate from Meta disclosure,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.106684,
gemini_advanced,Google,,,,3.77e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,"Benchmark-based (lmarena_score): 1332.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 3.77e+25 FLOP",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T19:50:21.106749,
hunyuan_large_vision,Tencent,,,,3.73e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.66e+25 (Medium); coding_score: 3.79e+25 (Medium) → weighted average: 3.73e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.109829,
yi_lightning_lite,01 AI,,,,3.73e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.78e+25 (Medium); coding_score: 3.69e+25 (Medium) → weighted average: 3.73e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.130186,
gemini_1.5_flash_002,Google,,,,3.71e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.84e+25 (Medium); coding_score: 3.58e+25 (Medium) → weighted average: 3.71e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.108814,
hunyuan_standard,Tencent,,,,3.71e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.71e+25 (Medium); coding_score: 3.71e+25 (Medium) → weighted average: 3.71e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.108672,
magistral_medium,Mistral,,,,3.69e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.51e+25 (Medium); coding_score: 3.87e+25 (Medium) → weighted average: 3.69e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.109088,
amazon_nova_experimental_chat_05_14,Amazon,,,,3.66e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,"Benchmark-based (lmarena_score): 1318.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 3.66e+25 FLOP",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T19:50:21.107682,
mistral_large,Mistral,,,,3.66e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.65e+25 (Medium); coding_score: 3.67e+25 (Medium) → weighted average: 3.66e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.108957,
claude_3_5_haiku,Anthropic,,,,3.65e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,"Benchmark-based (lmarena_score): 1317.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 3.65e+25 FLOP",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T19:50:21.108137,
athene,NexusFlow,,,,3.63e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,"Benchmark-based (lmarena_score): 1315.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 3.63e+25 FLOP",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T19:50:21.108505,
qwen2.5_plus,Alibaba,,,,3.63e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,"Benchmark-based (lmarena_score): 1315.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 3.63e+25 FLOP",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T19:50:21.108067,
amazon_nova_pro,Amazon,,,,3.62e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.59e+25 (Medium); coding_score: 3.65e+25 (Medium) → weighted average: 3.62e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.110406,
claude_3.5_haiku,Anthropic,,,,3.62e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.54e+25 (Medium); coding_score: 3.70e+25 (Medium) → weighted average: 3.62e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.130546,
claude_3.5_sonnet,Anthropic,,,,3.6e+25,medium,,company_disclosure,,not_sure,likely_above_1e25,Epoch AI: Low-precision estimate from benchmarks,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),y,2025-07-31T18:56:49.506343,
glm_4,Zhipu AI,,,,3.58e+25,medium,,benchmark_based,,not_sure,likely_above_1e25,"Benchmark-based (lmarena_score): Benchmark-based estimation: ELO 1275.0 vs reference llama_405b (ELO 1300, 3.80e+25 FLOP) with power law scaling α=3.0 = 3.58e+25 FLOP",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T18:48:13.588801,
qwen_plus,Alibaba,,,,3.46e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.42e+25 (Medium); coding_score: 3.49e+25 (Medium) → weighted average: 3.46e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.105691,
amazon_nova_lite,Amazon,,,,3.38e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.35e+25 (Medium); coding_score: 3.41e+25 (Medium) → weighted average: 3.38e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.112565,
gemini_1.5_flash_001,Google,,,,3.38e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,"Benchmark-based (lmarena_score): 1284.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 3.38e+25 FLOP",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T19:50:21.110976,
jamba_1.5_large,AI21 Labs,,,,3.38e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.42e+25 (Medium); coding_score: 3.34e+25 (Medium) → weighted average: 3.38e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.110538,
command_r_plus_08,Cohere,,,,3.36e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,"Benchmark-based (lmarena_score): 1281.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 3.36e+25 FLOP",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T19:50:21.111212,
reka_core,Reka AI,,,,3.34e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.49e+25 (Medium); coding_score: 3.19e+25 (Medium) → weighted average: 3.34e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.110653,
yi_large,01 AI,,,,3.32e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.37e+25 (Low); coding_score: 3.29e+25 (Medium) → weighted average: 3.32e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.130904,
phi_4,Microsoft,,,,3.29e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.26e+25 (Medium); coding_score: 3.32e+25 (Medium) → weighted average: 3.29e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.112646,
claude_3_sonnet,Anthropic,,,,3.26e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.27e+25 (Medium); coding_score: 3.24e+25 (Medium) → weighted average: 3.26e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.111145,
hunyuan_standard_256k,Tencent,,,,3.25e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.16e+25 (Medium); coding_score: 3.34e+25 (Medium) → weighted average: 3.25e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.113041,
command_r_plus,Cohere,,,,3.24e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,"Benchmark-based (lmarena_score): 1266.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 3.24e+25 FLOP",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T19:50:21.112119,
amazon_nova_micro,Amazon,,,,3.21e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.20e+25 (Medium); coding_score: 3.21e+25 (Medium) → weighted average: 3.21e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.112790,
command_r_08,Cohere,,,,3.14e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,"Benchmark-based (lmarena_score): 1253.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 3.14e+25 FLOP",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T19:50:21.112709,
reka_flash,Reka AI,,,,3.12e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.23e+25 (Medium); coding_score: 3.00e+25 (Medium) → weighted average: 3.12e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.111487,
claude_3_haiku,Anthropic,,,,3.07e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.09e+25 (Medium); coding_score: 3.06e+25 (Medium) → weighted average: 3.07e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.112411,
qwen_max,Alibaba,,,,3.07e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.08e+25 (Medium); coding_score: 3.06e+25 (Medium) → weighted average: 3.07e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.107904,
jamba_1.5_mini,AI21 Labs,,,,3.01e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.03e+25 (Medium); coding_score: 2.97e+25 (Low) → weighted average: 3.01e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.112897,
gemini_pro_dev_api,Google,,,,3.00e+25,low,Distant benchmark interpolation or single source,benchmark_based,,not_sure,uncertain,"Benchmark-based (lmarena_score): 1234.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 3.00e+25 FLOP",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T19:50:21.113583,
grok_2,xAI,,,,3.00e+25,high,Official disclosure or high-precision research estimate,epoch_estimate,Benchmark Based: 3.77e+25 (Medium),not_sure,confirmed_above_1e25,https://epoch.ai/data-insights/models-over-1e25-flop: High-precision estimate from xAI disclosure,LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T19:50:21.106816,
grok_2_08_13,xAI,,,,3.00e+25,high,Official disclosure or high-precision research estimate,epoch_estimate,Benchmark Based: 3.89e+25 (Medium),not_sure,confirmed_above_1e25,https://epoch.ai/data-insights/models-over-1e25-flop: High-precision estimate from xAI disclosure,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.129556,
grok_2_mini,xAI,,,,3.00e+25,high,Official disclosure or high-precision research estimate,epoch_estimate,Benchmark Based: 3.57e+25 (Medium),not_sure,confirmed_above_1e25,https://epoch.ai/data-insights/models-over-1e25-flop: High-precision estimate from xAI disclosure,LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T19:50:21.109340,
grok_2_mini_08_13,xAI,,,,3.00e+25,high,Official disclosure or high-precision research estimate,epoch_estimate,Benchmark Based: 3.70e+25 (Medium),not_sure,confirmed_above_1e25,https://epoch.ai/data-insights/models-over-1e25-flop: High-precision estimate from xAI disclosure,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.130382,
gemini_pro,Google,,,,2.91e+25,low,Distant benchmark interpolation or single source,benchmark_based,,not_sure,uncertain,"Benchmark-based (lmarena_score): 1222.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 2.91e+25 FLOP",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T19:50:21.114315,
mistral_medium,Mistral,,,,2.83e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 2.87e+25 (Low); coding_score: 2.79e+25 (Low) → weighted average: 2.83e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.103736,
claude_1,Anthropic,,,,2.82e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 2.93e+25 (Low); coding_score: 2.71e+25 (Low) → weighted average: 2.82e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.131236,
command_r,Cohere,,,,2.72e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 2.86e+25 (Low); coding_score: 2.58e+25 (Low) → weighted average: 2.72e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.113918,
phi_3_medium_4k,Microsoft,,,,2.64e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 2.68e+25 (Low); coding_score: 2.60e+25 (Low) → weighted average: 2.64e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.115509,
gemini_1.0_pro_001,Google,,,,2.61e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 2.75e+25 (Low); coding_score: 2.47e+25 (Low) → weighted average: 2.61e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.131522,
gpt_3.5_turbo,OpenAI,,,,2.59e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 2.63e+25 (Low); coding_score: 2.54e+25 (Low) → weighted average: 2.59e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.114508,
claude_instant_1,Anthropic,,,,2.58e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 2.61e+25 (Low); coding_score: 2.54e+25 (Low) → weighted average: 2.58e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.131670,
dbrx_instruct_preview,Databricks,,,,2.56e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 2.55e+25 (Low); coding_score: 2.58e+25 (Low) → weighted average: 2.56e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.116138,
phi_3_small_8k,Microsoft,,,,2.47e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 2.49e+25 (Low); coding_score: 2.45e+25 (Low) → weighted average: 2.47e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.117655,
phi_3_mini_4k_instruct_june,Microsoft,,,,2.42e+25,low,Distant benchmark interpolation or single source,benchmark_based,,not_sure,uncertain,"Benchmark-based (lmarena_score): 1149.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 2.42e+25 FLOP",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T19:50:21.119832,
snowflake_arctic,Snowflake,,,,2.38e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 2.44e+25 (Low); coding_score: 2.31e+25 (Low) → weighted average: 2.38e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.117260,
palm_2,Google,,,,2.37e+25,low,Distant benchmark interpolation or single source,benchmark_based,,not_sure,uncertain,"Benchmark-based (lmarena_score): 1141.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 2.37e+25 FLOP",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T19:50:21.121063,
phi_3_mini_128k,Microsoft,,,,2.35e+25,low,Distant benchmark interpolation or single source,benchmark_based,,not_sure,uncertain,"Benchmark-based (lmarena_score): 1138.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 2.35e+25 FLOP",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T19:50:21.122383,
phi_3_mini_4k_instruct_june_24,Microsoft,,,,2.30e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 2.30e+25 (Low); coding_score: 2.29e+25 (Low) → weighted average: 2.30e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.132085,
phi_3_mini_4k,Microsoft,,,,2.29e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 2.26e+25 (Low); coding_score: 2.32e+25 (Low) → weighted average: 2.29e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.122821,
openchat,OpenChat,,,,2.28e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,not_sure,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 2.40e+25 (Low); coding_score: 2.17e+25 (Low) → weighted average: 2.28e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.116856,
gemini_1.5_pro_001,Google,,300000000000.0,known_specification:gemini_1.5_pro,2.16e+25,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 3.67e+25 (Medium),not_sure,likely_above_1e25,"Known model specification 'gemini_1.5_pro': Chinchilla scaling law: 6 × 300,000,000,000 params × 12,000,000,000,000 tokens = 2.16e+25 FLOP",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T19:50:21.107615,
gemini_1.5_pro_002,Google,,300000000000.0,known_specification:gemini_1.5_pro,2.16e+25,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 4.00e+25 (Medium),not_sure,likely_above_1e25,"Known model specification 'gemini_1.5_pro': Chinchilla scaling law: 6 × 300,000,000,000 params × 12,000,000,000,000 tokens = 2.16e+25 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.105378,
gpt_4,OpenAI,,1760000000000.0,known_specification:gpt_4,2.10e+25,medium,Reliable research estimate from industry analysis,epoch_estimate,Scaling Laws: 1.37e+26 (Medium); Benchmark Based: 3.33e+25 (Medium),not_sure,likely_above_1e25,https://epoch.ai/data-insights/models-over-1e25-flop: Low-precision estimate from scaling analysis,LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T19:50:21.110775,
gpt_4.1_mini,OpenAI,,1760000000000.0,known_specification:gpt_4,2.10e+25,medium,Reliable research estimate from industry analysis,epoch_estimate,Scaling Laws: 1.37e+26 (Medium); Benchmark Based: 4.37e+25 (Medium),not_sure,likely_above_1e25,https://epoch.ai/data-insights/models-over-1e25-flop: Low-precision estimate from scaling analysis,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.104165,
gpt_4.1_nano,OpenAI,,1760000000000.0,known_specification:gpt_4,2.10e+25,medium,Reliable research estimate from industry analysis,epoch_estimate,Scaling Laws: 1.37e+26 (Medium); Benchmark Based: 3.86e+25 (Medium),not_sure,likely_above_1e25,https://epoch.ai/data-insights/models-over-1e25-flop: Low-precision estimate from scaling analysis,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.107280,
gpt_4_preview,OpenAI,,1760000000000.0,known_specification:gpt_4,2.10e+25,medium,Reliable research estimate from industry analysis,epoch_estimate,Scaling Laws: 1.37e+26 (Medium); Benchmark Based: 3.55e+25 (Medium),not_sure,likely_above_1e25,https://epoch.ai/data-insights/models-over-1e25-flop: Low-precision estimate from scaling analysis,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.108333,
gpt_4_turbo,OpenAI,,1760000000000.0,known_specification:gpt_4,2.10e+25,medium,Reliable research estimate from industry analysis,epoch_estimate,Scaling Laws: 1.37e+26 (Medium); Benchmark Based: 3.67e+25 (Medium),not_sure,likely_above_1e25,https://epoch.ai/data-insights/models-over-1e25-flop: Low-precision estimate from scaling analysis,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.107377,
claude_3_opus,Anthropic,,175000000000.0,known_specification:claude_3_opus,1.60e+25,medium,Reliable research estimate from industry analysis,epoch_estimate,Scaling Laws: 8.40e+24 (Medium); Benchmark Based: 3.58e+25 (Medium),not_sure,likely_above_1e25,https://epoch.ai/data-insights/models-over-1e25-flop: Low-precision estimate from industry analysis,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.107527,
qwen3_235b,Alibaba,,235000000000.0,known_specification:qwen3_235b,1.41e+25,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 4.62e+25 (Medium),not_sure,likely_above_1e25,"Known model specification 'qwen3_235b': Chinchilla scaling law: 6 × 235,000,000,000 params × 10,000,000,000,000 tokens = 1.41e+25 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.104301,
qwen3_235b_a22b,Alibaba,,235000000000.0,known_specification:qwen3_235b,1.41e+25,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 4.83e+25 (Medium),not_sure,likely_above_1e25,"Known model specification 'qwen3_235b': Chinchilla scaling law: 6 × 235,000,000,000 params × 10,000,000,000,000 tokens = 1.41e+25 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.103006,
nemotron_4_340b,Nvidia,,340000000000.0,extracted_from_name,1.04e+25,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 3.23e+25 (Medium),not_sure,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 340,000,000,000 params × 5,100,000,000,000 tokens = 1.04e+25 FLOP (Generic estimate: 340B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:50:21.111339,
hunyuan_standard_vision,Tencent,,,,,speculative,Speculative confidence from manual research method,manual_research,,not_sure,uncertain,,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:28:48.816405,
pixtral_large,Mistral,,,,,speculative,Speculative confidence from manual research method,manual_research,,not_sure,uncertain,,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:28:48.815733,
qwen_vl_max,Alibaba,,,,,speculative,Speculative confidence from manual research method,manual_research,,not_sure,uncertain,,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:28:48.815814,
step_1o_vision_32k,StepFun,,,,,speculative,Speculative confidence from manual research method,manual_research,,not_sure,uncertain,,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:28:48.815556,
step_1v_32k,StepFun,,,,,speculative,Speculative confidence from manual research method,manual_research,,not_sure,uncertain,,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:28:48.815995,
yi_vision,01 AI,,,,,speculative,Speculative confidence from manual research method,manual_research,,not_sure,uncertain,,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T19:28:48.816639,
