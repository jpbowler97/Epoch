model,developer,release_date,parameters,parameter_source,training_flop,confidence,confidence_explanation,estimation_method,alternative_methods,threshold_classification,reasoning,sources,verified,last_updated,notes,blacklist_status
o3_mini,OpenAI,,,,4.89e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 4.09e+25 (Medium); coding_score: 4.36e+25 (Medium); aai_score: 6.51e+25 (Medium); mmlu_pro_score: 4.61e+25 (Medium) → weighted average: 4.89e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),y,2025-08-11T21:33:55.830980,Moved from above_1e25_flop.csv by manual review. Reason: It's a mini model so pretty sure it's below 1e25 FLOP,allowed
grok_3_mini,xAI,,,,4.379999999999999e+25,medium,,benchmark_based,,high_confidence_below_1e25,"Benchmark-based (openlm_arena_elo): Benchmark-based estimation: ELO 1363.0 vs reference llama_405b (ELO 1300, 3.80e+25 FLOP) with power law scaling α=3.0 = 4.38e+25 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),y,2025-08-01T15:52:46.887087,Moved from above_1e25_flop.csv by manual review. Reason: This is a mini model so likely smaller than 1e25,
gemini_1.5_flash,Google,,,,3.11e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 5 benchmarks: superclue_overall: 3.07e+25 (Medium); superclue_math: 2.42e+25 (Low); superclue_reasoning: 9.65e+24 (Low); superclue_code: 3.39e+25 (Medium); superclue_agents: 4.75e+25 (Medium) → weighted average: 3.11e+25 FLOP,https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),y,2025-08-04T20:21:02.232619,Moved from above_1e25_flop.csv by manual review. Reason: only gemini 2.0 or later versions are over 1e25 FLOP,allowed
sora,OpenAI,,,,1.00e+25,low,Distant benchmark interpolation or single source,benchmark_based,,high_confidence_below_1e25,Multi-benchmark estimation from 2 benchmarks: video_arena_elo: 1.00e+25 (Medium); video_quality: 1.00e+25 (Medium) → weighted average: 1.00e+25 FLOP,https://artificialanalysis.ai/text-to-video/arena (Artificial Analysis Video Arena - Text-to-video model rankings),,2025-08-15T20:32:45.090648,,allowed
athene,NexusFlow,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 3.63e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited computational resources for large-scale training,CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.057287,,allowed
baichuan_4,Unknown,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 3.10e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Models with unidentified developers cannot be evaluated for resource availability,https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T20:32:45.092015,,allowed
command_a,Cohere,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 3.56e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Smaller AI company with limited computational budget for frontier models,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.078368,,allowed
command_a_03,Cohere,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 3.90e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Smaller AI company with limited computational budget for frontier models,CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.052481,,allowed
command_r,Cohere,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 1.50e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Smaller AI company with limited computational budget for frontier models,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.063444,,allowed
command_r_08,Cohere,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 3.14e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Smaller AI company with limited computational budget for frontier models,CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.062221,,allowed
command_r_plus,Cohere,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 3.24e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Smaller AI company with limited computational budget for frontier models,CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.061248,,allowed
command_r_plus_08,Cohere,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 3.36e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Smaller AI company with limited computational budget for frontier models,CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.060108,,allowed
dbrx_instruct_preview,Databricks,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 2.56e+25 (Low),high_confidence_below_1e25,"FLOP estimate capped at 9.9e+24 due to resource constraint policy: Focus on enterprise solutions, limited frontier model training resources",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.069861,,allowed
doubao_pro,ByteDance,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 3.49e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited evidence of 1e25+ FLOP computational budget allocation,https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T20:32:45.091268,,allowed
doubao_seed_1.6,ByteDance,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 4.90e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited evidence of 1e25+ FLOP computational budget allocation,https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T20:32:45.090846,,allowed
glm,Zhipu AI,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 5.76e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited computational resources for 1e25+ FLOP training runs,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.076789,,allowed
glm_4,Zhipu AI,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 3.07e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited computational resources for 1e25+ FLOP training runs,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.060561,,allowed
glm_4.5_air,Zhipu AI,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 5.08e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited computational resources for 1e25+ FLOP training runs,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.077486,,allowed
glm_4_flash,Zhipu AI,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 2.60e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited computational resources for 1e25+ FLOP training runs,https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T20:32:45.092462,,allowed
glm_4_plus,Zhipu AI,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 3.69e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited computational resources for 1e25+ FLOP training runs,https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T20:32:45.053131,,allowed
hunyuan_large,Tencent,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 3.88e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited evidence of computational budget allocation for frontier AI models,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.055156,,allowed
hunyuan_large_vision,Tencent,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 3.73e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited evidence of computational budget allocation for frontier AI models,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.058551,,allowed
hunyuan_pro,Tencent,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 3.60e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited evidence of computational budget allocation for frontier AI models,https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T20:32:45.091146,,allowed
hunyuan_standard,Tencent,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 3.71e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited evidence of computational budget allocation for frontier AI models,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.057458,,allowed
hunyuan_standard_256k,Tencent,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 3.25e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited evidence of computational budget allocation for frontier AI models,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.062707,,allowed
hunyuan_turbo,Tencent,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 4.08e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited evidence of computational budget allocation for frontier AI models,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.053266,,allowed
hunyuan_turbos,Tencent,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 4.59e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited evidence of computational budget allocation for frontier AI models,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.048221,,allowed
internlm_3,Unknown,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 2.65e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Models with unidentified developers cannot be evaluated for resource availability,https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T20:32:45.092318,,allowed
jamba_1.5_large,AI21 Labs,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 2.39e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited access to large-scale GPU infrastructure,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.059332,,allowed
jamba_1.5_mini,AI21 Labs,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 3.00e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited access to large-scale GPU infrastructure,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.062548,,allowed
lumiere,Unknown,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 1.10e+25 (Medium),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Models with unidentified developers cannot be evaluated for resource availability,https://physics-iq.github.io/ (Physics-IQ - Benchmark for physical understanding in video generation models),,2025-08-15T20:32:45.090324,,allowed
minimax_01,MiniMax,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 3.36e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited computational resources for 1e25+ FLOP training runs,https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T20:32:45.091649,,allowed
minimax_m1,MiniMax,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 5.09e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited computational resources for 1e25+ FLOP training runs,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.048367,,allowed
moonshot,Unknown,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 3.30e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Models with unidentified developers cannot be evaluated for resource availability,https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T20:32:45.091831,,allowed
o4_mini,Unknown,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 5.47e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Models with unidentified developers cannot be evaluated for resource availability,https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T20:32:45.047366,,allowed
openchat,OpenChat,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 2.28e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Open source project with limited computational resources,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.070595,,allowed
phi_3_medium_4k,Microsoft,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 1.87e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Primarily partners with OpenAI rather than training proprietary frontier models,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.068355,,allowed
phi_3_mini_128k,Microsoft,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 2.35e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Primarily partners with OpenAI rather than training proprietary frontier models,CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.074072,,allowed
phi_3_mini_4k,Microsoft,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 2.29e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Primarily partners with OpenAI rather than training proprietary frontier models,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.074324,,allowed
phi_3_mini_4k_instruct_june,Microsoft,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 2.42e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Primarily partners with OpenAI rather than training proprietary frontier models,CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.073021,,allowed
phi_3_mini_4k_instruct_june_24,Microsoft,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 2.30e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Primarily partners with OpenAI rather than training proprietary frontier models,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.088924,,allowed
phi_3_small_8k,Microsoft,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 2.47e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Primarily partners with OpenAI rather than training proprietary frontier models,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.071453,,allowed
phi_4,Microsoft,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 2.99e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Primarily partners with OpenAI rather than training proprietary frontier models,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.062100,,allowed
pika,Pika Labs,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 1.10e+25 (Medium),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited computational resources for 1e25+ FLOP training runs,https://physics-iq.github.io/ (Physics-IQ - Benchmark for physical understanding in video generation models),,2025-08-15T20:32:45.090609,,allowed
reka_core,Reka AI,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 3.34e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Smaller AI company with limited computational budget,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.059461,,allowed
reka_flash,Reka AI,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 3.12e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Smaller AI company with limited computational budget,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.060399,,allowed
snowflake_arctic,Snowflake,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 2.38e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Data platform company without large-scale AI model training focus,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.071170,,allowed
step_1o_turbo,StepFun,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 4.33e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited computational resources for 1e25+ FLOP training runs,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.077989,,allowed
step_2,StepFun,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 4.02e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited computational resources for 1e25+ FLOP training runs,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.053816,,allowed
step_2_16k,StepFun,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 3.41e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited computational resources for 1e25+ FLOP training runs,https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T20:32:45.091465,,allowed
videopoet,Unknown,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 1.10e+25 (Medium),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Models with unidentified developers cannot be evaluated for resource availability,https://physics-iq.github.io/ (Physics-IQ - Benchmark for physical understanding in video generation models),,2025-08-15T20:32:45.090202,,allowed
yi_large,01 AI,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 2.36e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited computational resources for 1e25 FLOP training runs,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.087723,,allowed
yi_lightning,01 AI,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 3.67e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited computational resources for 1e25 FLOP training runs,https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T20:32:45.055009,,allowed
yi_lightning_lite,01 AI,,,,9.90e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 3.73e+25 (Low),high_confidence_below_1e25,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited computational resources for 1e25 FLOP training runs,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.086799,,allowed
seedance,Unknown,,,,9.25e+24,low,Distant benchmark interpolation or single source,benchmark_based,,high_confidence_below_1e25,Multi-benchmark estimation from 2 benchmarks: video_arena_elo: 9.31e+24 (Low); video_quality: 9.19e+24 (Low) → weighted average: 9.25e+24 FLOP,https://artificialanalysis.ai/text-to-video/arena (Artificial Analysis Video Arena - Text-to-video model rankings),,2025-08-15T20:32:45.093004,,allowed
waver,Unknown,,,,8.81e+24,low,Distant benchmark interpolation or single source,benchmark_based,,high_confidence_below_1e25,Multi-benchmark estimation from 2 benchmarks: video_arena_elo: 8.90e+24 (Low); video_quality: 8.72e+24 (Low) → weighted average: 8.81e+24 FLOP,https://artificialanalysis.ai/text-to-video/arena (Artificial Analysis Video Arena - Text-to-video model rankings),,2025-08-15T20:32:45.093046,,allowed
deepseek_coder_v2,DeepSeek,,236000000000.0,known_specification:deepseek_coder_v2,8.50e+24,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 3.26e+25 (Low),high_confidence_below_1e25,"Known model specification 'deepseek_coder_v2': Chinchilla scaling law: 6 × 236,000,000,000 params × 6,000,000,000,000 tokens = 8.50e+24 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.061465,,allowed
runway_gen3,Unknown,,,,7.87e+24,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,high_confidence_below_1e25,Multi-benchmark estimation from 2 benchmarks: video_arena_elo: 8.22e+24 (Low); video_quality: 7.52e+24 (Low) → weighted average: 7.87e+24 FLOP,https://artificialanalysis.ai/text-to-video/arena (Artificial Analysis Video Arena - Text-to-video model rankings),,2025-08-04T18:55:00.258921,,allowed
kling,Unknown,,,,7.35e+24,low,Distant benchmark interpolation or single source,benchmark_based,,high_confidence_below_1e25,Multi-benchmark estimation from 2 benchmarks: video_arena_elo: 7.76e+24 (Low); video_quality: 6.93e+24 (Low) → weighted average: 7.35e+24 FLOP,https://artificialanalysis.ai/text-to-video/arena (Artificial Analysis Video Arena - Text-to-video model rankings),,2025-08-15T20:32:45.093120,,allowed
llama_3.1_70b,Meta,,70000000000.0,known_specification:llama_3.1_70b,6.30e+24,high,Known parameters with documented training tokens,scaling_laws,Benchmark Based: 2.16e+25 (Low),high_confidence_below_1e25,"Known model specification 'llama_3.1_70b': Chinchilla scaling law: 6 × 70,000,000,000 params × 15,000,000,000,000 tokens = 6.30e+24 FLOP",https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T20:32:45.058923,,allowed
llama_3_70b,Meta,,70000000000.0,known_specification:llama_3_70b,6.30e+24,high,Known parameters with documented training tokens,scaling_laws,Benchmark Based: 2.26e+25 (Low),high_confidence_below_1e25,"Known model specification 'llama_3_70b': Chinchilla scaling law: 6 × 70,000,000,000 params × 15,000,000,000,000 tokens = 6.30e+24 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.060714,,allowed
llama_3.1_nemotron_ultra_253b,Nvidia,,253000000000.0,extracted_from_name,5.76e+24,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 4.17e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 253,000,000,000 params × 3,795,000,000,000 tokens = 5.76e+24 FLOP (Modern large model: 253B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.787773,,
llama_3.1_nemotron_ultra_253b_v1,Meta,,253000000000.0,extracted_from_name,5.76e+24,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 4.59e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 253,000,000,000 params × 3,795,000,000,000 tokens = 5.76e+24 FLOP (Modern large model: 253B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.050561,,allowed
qwen3_235b_a22b,Alibaba,,235000000000.0,extracted_from_name,4.97e+24,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 6.30e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 235,000,000,000 params × 3,525,000,000,000 tokens = 4.97e+24 FLOP (Modern large model: 235B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.047268,,allowed
deepseek_r1,DeepSeek,,671000000000.0,known_specification:deepseek_r1,3.00e+24,high,Official disclosure or high-precision research estimate,epoch_estimate,Scaling Laws: 6.04e+25 (Low); Benchmark Based: 5.10e+25 (Low),high_confidence_below_1e25,https://epoch.ai/gradient-updates/what-went-into-training-deepseek-r1,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.046461,,allowed
falcon_180b,TII,,180000000000.0,extracted_from_name,2.92e+24,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.40e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 180,000,000,000 params × 2,700,000,000,000 tokens = 2.92e+24 FLOP (Generic estimate: 180B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.072670,,allowed
zephyr_orpo_141b,HuggingFace,,141000000000.0,extracted_from_name,1.79e+24,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 2.66e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 141,000,000,000 params × 2,115,000,000,000 tokens = 1.79e+24 FLOP (Generic estimate: 141B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.809406,,
gpt_oss_120b,OpenAI,,120000000000.0,extracted_from_name,1.30e+24,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 5.74e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 120,000,000,000 params × 1,800,000,000,000 tokens = 1.30e+24 FLOP (Generic estimate: 120B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.077717,,allowed
qwen1.5_110b,Alibaba,,110000000000.0,extracted_from_name,1.16e+24,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.09e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 110,000,000,000 params × 1,760,000,000,000 tokens = 1.16e+24 FLOP (Chinese model: 110B params * 16 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.062962,,allowed
llama_3.2_90b_vision,Meta,,90000000000.0,extracted_from_name,9.72e+23,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.09e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 90,000,000,000 params × 1,800,000,000,000 tokens = 9.72e+23 FLOP (Modern model: 90B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.089807,,allowed
llama_2_70b,Meta,,70000000000.0,known_specification:llama_2_70b,8.40e+23,high,Known parameters with documented training tokens,scaling_laws,Benchmark Based: 1.46e+25 (Low),high_confidence_below_1e25,"Known model specification 'llama_2_70b': Chinchilla scaling law: 6 × 70,000,000,000 params × 2,000,000,000,000 tokens = 8.40e+23 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.071694,,allowed
llama_3.1_8b,Meta,,8000000000.0,known_specification:llama_3.1_8b,7.20e+23,high,Known parameters with documented training tokens,scaling_laws,Benchmark Based: 1.92e+25 (Low),high_confidence_below_1e25,"Known model specification 'llama_3.1_8b': Chinchilla scaling law: 6 × 8,000,000,000 params × 15,000,000,000,000 tokens = 7.20e+23 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.065094,,allowed
llama_3_8b,Meta,,8000000000.0,known_specification:llama_3_8b,7.20e+23,high,Known parameters with documented training tokens,scaling_laws,Benchmark Based: 1.66e+25 (Low),high_confidence_below_1e25,"Known model specification 'llama_3_8b': Chinchilla scaling law: 6 × 8,000,000,000 params × 15,000,000,000,000 tokens = 7.20e+23 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.064103,,allowed
llama_3.1_nemotron_70b,Nvidia,,70000000000.0,extracted_from_name,5.88e+23,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 3.75e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,400,000,000,000 tokens = 5.88e+23 FLOP (Modern model: 70B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.801637,,
llama_3.1_tulu_3_70b,Ai2,,70000000000.0,extracted_from_name,5.88e+23,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 3.48e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,400,000,000,000 tokens = 5.88e+23 FLOP (Modern model: 70B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.802087,,
llama_3.3_70b,Meta,,70000000000.0,extracted_from_name,5.88e+23,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.63e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,400,000,000,000 tokens = 5.88e+23 FLOP (Modern model: 70B params * 20 tokens/param)",https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T20:32:45.056604,,allowed
athene_v2_chat_72b,NexusFlow,,72000000000.0,extracted_from_name,5.60e+23,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 3.93e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 72,000,000,000 params × 1,296,000,000,000 tokens = 5.60e+23 FLOP (Specialized model: 72B params * 18 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.086467,,allowed
codellama_70b,Meta,,70000000000.0,extracted_from_name,5.29e+23,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.31e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,260,000,000,000 tokens = 5.29e+23 FLOP (Specialized model: 70B params * 18 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.073799,,allowed
qwen1.5_72b,Alibaba,,72000000000.0,extracted_from_name,4.98e+23,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.84e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 72,000,000,000 params × 1,152,000,000,000 tokens = 4.98e+23 FLOP (Chinese model: 72B params * 16 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.063056,,allowed
molmo_72b,Ai2,,72000000000.0,extracted_from_name,4.67e+23,low,Extracted parameters with uncertain training tokens,scaling_laws,,high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 72,000,000,000 params × 1,080,000,000,000 tokens = 4.67e+23 FLOP (Generic estimate: 72B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.823172,,
athene_70b,NexusFlow,,70000000000.0,extracted_from_name,4.41e+23,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 3.61e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,050,000,000,000 tokens = 4.41e+23 FLOP (Generic estimate: 70B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.058252,,allowed
llama2_70b_steerlm,Nvidia,,70000000000.0,extracted_from_name,4.41e+23,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.52e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,050,000,000,000 tokens = 4.41e+23 FLOP (Generic estimate: 70B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.072042,,allowed
nv_llama2_70b_steerlm,Nvidia,,70000000000.0,extracted_from_name,4.41e+23,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 2.20e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,050,000,000,000 tokens = 4.41e+23 FLOP (Generic estimate: 70B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.822656,,
pplx_70b_online,Perplexity AI,,70000000000.0,extracted_from_name,4.41e+23,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 2.20e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,050,000,000,000 tokens = 4.41e+23 FLOP (Generic estimate: 70B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.822751,,
tulu_2_dpo_70b,Ai2,,70000000000.0,extracted_from_name,4.41e+23,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 2.50e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,050,000,000,000 tokens = 4.41e+23 FLOP (Generic estimate: 70B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.812531,,
wizardlm_70b,Microsoft,,70000000000.0,extracted_from_name,4.41e+23,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 2.41e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,050,000,000,000 tokens = 4.41e+23 FLOP (Generic estimate: 70B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.810522,,
deepseek_llm_67b,DeepSeek,,67000000000.0,extracted_from_name,4.04e+23,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 1.65e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 67,000,000,000 params × 1,005,000,000,000 tokens = 4.04e+23 FLOP (Generic estimate: 67B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.070234,,allowed
qwen2.5_72b,Alibaba,,72000000000.0,extracted_from_name,3.73e+23,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.74e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 72,000,000,000 params × 864,000,000,000 tokens = 3.73e+23 FLOP (Mid-era model: 72B params * 12 tokens/param)",https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T20:32:45.058348,,allowed
qwen2.5_vl_72b,Alibaba,,72000000000.0,extracted_from_name,3.73e+23,medium,Known parameters with estimated training tokens,scaling_laws,,high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 72,000,000,000 params × 864,000,000,000 tokens = 3.73e+23 FLOP (Mid-era model: 72B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.089108,,allowed
qwen2_72b,Alibaba,,72000000000.0,extracted_from_name,3.73e+23,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.44e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 72,000,000,000 params × 864,000,000,000 tokens = 3.73e+23 FLOP (Mid-era model: 72B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.061138,,allowed
qwen2_vl_72b,Alibaba,,72000000000.0,extracted_from_name,3.73e+23,medium,Known parameters with estimated training tokens,scaling_laws,,high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 72,000,000,000 params × 864,000,000,000 tokens = 3.73e+23 FLOP (Mid-era model: 72B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.089415,,allowed
llama_3.1_nemotron_51b,Nvidia,,51000000000.0,extracted_from_name,3.12e+23,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 3.27e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 51,000,000,000 params × 1,020,000,000,000 tokens = 3.12e+23 FLOP (Modern model: 51B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.802247,,
llama_3.3_nemotron_49b_super,Nvidia,,49000000000.0,extracted_from_name,2.88e+23,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 3.72e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 49,000,000,000 params × 980,000,000,000 tokens = 2.88e+23 FLOP (Modern model: 49B params * 20 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T21:13:48.797907,,
llama_3.3_nemotron_49b_super_v1,Nvidia,,49000000000.0,extracted_from_name,2.88e+23,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 3.72e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 49,000,000,000 params × 980,000,000,000 tokens = 2.88e+23 FLOP (Modern model: 49B params * 20 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.054803,,allowed
llama_3.3_nemotron_super_49b,Nvidia,,49000000000.0,extracted_from_name,2.88e+23,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 4.00e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 49,000,000,000 params × 980,000,000,000 tokens = 2.88e+23 FLOP (Modern model: 49B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.820966,,
llama_3.3_nemotron_super_49b_v1,Meta,,49000000000.0,extracted_from_name,2.88e+23,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 4.06e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 49,000,000,000 params × 980,000,000,000 tokens = 2.88e+23 FLOP (Modern model: 49B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.078956,,allowed
llama_3.3_nemotron_super_49b_v1.5,Meta,,49000000000.0,extracted_from_name,2.88e+23,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 4.97e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 49,000,000,000 params × 980,000,000,000 tokens = 2.88e+23 FLOP (Modern model: 49B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.078113,,allowed
codellama_34b,Meta,,34000000000.0,extracted_from_name,1.39e+23,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.15e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 34,000,000,000 params × 680,000,000,000 tokens = 1.39e+23 FLOP (Modern model: 34B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.073413,,allowed
qwen3_32b,Alibaba,,32000000000.0,extracted_from_name,1.23e+23,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 4.51e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 640,000,000,000 tokens = 1.23e+23 FLOP (Modern model: 32B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.052911,,allowed
yi_1.5_34b,01 AI,,34000000000.0,extracted_from_name,1.11e+23,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.25e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 34,000,000,000 params × 544,000,000,000 tokens = 1.11e+23 FLOP (Chinese model: 34B params * 16 tokens/param)",https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T20:32:45.064770,,allowed
yi_34b,01 AI,,34000000000.0,extracted_from_name,1.11e+23,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.55e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 34,000,000,000 params × 544,000,000,000 tokens = 1.11e+23 FLOP (Chinese model: 34B params * 16 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.070428,,allowed
qwen3_30b,Alibaba,,30000000000.0,extracted_from_name,1.08e+23,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 4.21e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 30,000,000,000 params × 600,000,000,000 tokens = 1.08e+23 FLOP (Modern model: 30B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.054674,,allowed
qwen1.5_32b,Alibaba,,32000000000.0,extracted_from_name,9.83e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.70e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 512,000,000,000 tokens = 9.83e+22 FLOP (Chinese model: 32B params * 16 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.065234,,allowed
guanaco_33b,UW,,33000000000.0,extracted_from_name,9.80e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.30e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 33,000,000,000 params × 495,000,000,000 tokens = 9.80e+22 FLOP (Generic estimate: 33B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.074407,,allowed
vicuna_33b,LMSYS,,33000000000.0,extracted_from_name,9.8e+22,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 2.36e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 33,000,000,000 params × 495,000,000,000 tokens = 9.80e+22 FLOP (Generic estimate: 33B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.813401,,
aya_expanse_32b,Cohere,,32000000000.0,extracted_from_name,9.22e+22,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 3.20e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 480,000,000,000 tokens = 9.22e+22 FLOP (Generic estimate: 32B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.822168,,
aya_vision_32b,Cohere,,32000000000.0,extracted_from_name,9.22e+22,low,Extracted parameters with uncertain training tokens,scaling_laws,,high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 480,000,000,000 tokens = 9.22e+22 FLOP (Generic estimate: 32B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.823384,,
c4ai_aya_expanse_32b,Cohere,,32000000000.0,extracted_from_name,9.22e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 3.26e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 480,000,000,000 tokens = 9.22e+22 FLOP (Generic estimate: 32B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.061003,,allowed
olmo_2_32b,Ai2,,32000000000.0,extracted_from_name,9.22e+22,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 3.19e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 480,000,000,000 tokens = 9.22e+22 FLOP (Generic estimate: 32B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.806630,,
qwq_32b,Alibaba,,32000000000.0,extracted_from_name,9.22e+22,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 4.23e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 480,000,000,000 tokens = 9.22e+22 FLOP (Generic estimate: 32B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.794678,,
qwq_32b_preview,Alibaba,,32000000000.0,extracted_from_name,9.22e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.58e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 480,000,000,000 tokens = 9.22e+22 FLOP (Generic estimate: 32B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.071825,,allowed
gemma_3_27b,Google,,27000000000.0,extracted_from_name,8.75e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 4.36e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 27,000,000,000 params × 540,000,000,000 tokens = 8.75e+22 FLOP (Modern model: 27B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.787558,,
llama_2_7b,Meta,,7000000000.0,known_specification:llama_2_7b,8.40e+22,high,Known parameters with documented training tokens,scaling_laws,Benchmark Based: 2.20e+25 (Low),high_confidence_below_1e25,"Known model specification 'llama_2_7b': Chinchilla scaling law: 6 × 7,000,000,000 params × 2,000,000,000,000 tokens = 8.40e+22 FLOP",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.074816,,allowed
mpt_30b,MosaicML,,30000000000.0,extracted_from_name,8.1e+22,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 2.13e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 30,000,000,000 params × 450,000,000,000 tokens = 8.10e+22 FLOP (Generic estimate: 30B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.815135,,
qwen2.5_coder_32b,Alibaba,,32000000000.0,extracted_from_name,7.37e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.78e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 384,000,000,000 tokens = 7.37e+22 FLOP (Mid-era model: 32B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.060951,,allowed
qwen2.5_vl_32b,Alibaba,,32000000000.0,extracted_from_name,7.37e+22,medium,Known parameters with estimated training tokens,scaling_laws,,high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 384,000,000,000 tokens = 7.37e+22 FLOP (Mid-era model: 32B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.089024,,allowed
internvl2_26b,OpenGVLab,,26000000000.0,extracted_from_name,6.08e+22,low,Extracted parameters with uncertain training tokens,scaling_laws,,high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 26,000,000,000 params × 390,000,000,000 tokens = 6.08e+22 FLOP (Generic estimate: 26B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.823259,,
gemma_2_27b,Google,,27000000000.0,extracted_from_name,5.25e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 3.27e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 27,000,000,000 params × 324,000,000,000 tokens = 5.25e+22 FLOP (Mid-era model: 27B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.802802,,
mixtral_8x22b_instruct,Mistral,,22000000000.0,extracted_from_name,5.23e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 1.97e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 22,000,000,000 params × 396,000,000,000 tokens = 5.23e+22 FLOP (Specialized model: 22B params * 18 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.063289,,allowed
mixtral_8x22b,Mistral,,22000000000.0,extracted_from_name,4.36e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.08e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 22,000,000,000 params × 330,000,000,000 tokens = 4.36e+22 FLOP (Generic estimate: 22B params * 15 tokens/param)",https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T20:32:45.092706,,allowed
mistral_small_24b,Mistral,,24000000000.0,extracted_from_name,4.15e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 3.31e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 24,000,000,000 params × 288,000,000,000 tokens = 4.15e+22 FLOP (Mid-era model: 24B params * 12 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.060788,,allowed
mistral_small_3.1_24b,Mistral,,24000000000.0,extracted_from_name,4.15e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.92e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 24,000,000,000 params × 288,000,000,000 tokens = 4.15e+22 FLOP (Mid-era model: 24B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.058699,,allowed
mistral_small_3_24b,Mistral,,24000000000.0,extracted_from_name,4.15e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.74e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 24,000,000,000 params × 288,000,000,000 tokens = 4.15e+22 FLOP (Mid-era model: 24B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.087574,,allowed
reka_flash_21b,Reka AI,,21000000000.0,extracted_from_name,3.97e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.97e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 21,000,000,000 params × 315,000,000,000 tokens = 3.97e+22 FLOP (Generic estimate: 21B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.063504,,allowed
reka_flash_21b_online,Reka AI,,21000000000.0,extracted_from_name,3.97e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 3.01e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 21,000,000,000 params × 315,000,000,000 tokens = 3.97e+22 FLOP (Generic estimate: 21B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.063112,,allowed
gpt_oss_20b,OpenAI,,20000000000.0,extracted_from_name,3.60e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 4.48e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 20,000,000,000 params × 300,000,000,000 tokens = 3.60e+22 FLOP (Generic estimate: 20B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.078844,,allowed
internlm2.5_20b,InternLM,,20000000000.0,extracted_from_name,3.6e+22,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 2.84e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 20,000,000,000 params × 300,000,000,000 tokens = 3.60e+22 FLOP (Generic estimate: 20B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.822379,,
internlm2_5_20b,InternLM,,20000000000.0,extracted_from_name,3.60e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.76e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 20,000,000,000 params × 300,000,000,000 tokens = 3.60e+22 FLOP (Generic estimate: 20B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.069278,,allowed
llama_4_maverick_17b_128e,Meta,,17000000000.0,extracted_from_name,3.47e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 4.18e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 17,000,000,000 params × 340,000,000,000 tokens = 3.47e+22 FLOP (Modern model: 17B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.054757,,allowed
llama_4_scout_17b_16e,Meta,,17000000000.0,extracted_from_name,3.47e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 3.51e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 17,000,000,000 params × 340,000,000,000 tokens = 3.47e+22 FLOP (Modern model: 17B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.056173,,allowed
qwen1.5_14b,Alibaba,,14000000000.0,extracted_from_name,1.88e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.60e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 14,000,000,000 params × 224,000,000,000 tokens = 1.88e+22 FLOP (Chinese model: 14B params * 16 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.069379,,allowed
qwen_14b,Alibaba,,14000000000.0,extracted_from_name,1.88e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.37e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 14,000,000,000 params × 224,000,000,000 tokens = 1.88e+22 FLOP (Chinese model: 14B params * 16 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.073666,,allowed
rwkv_4_raven_14b,RWKV,,14000000000.0,extracted_from_name,1.76e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 1.82e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 14,000,000,000 params × 210,000,000,000 tokens = 1.76e+22 FLOP (Generic estimate: 14B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.075563,,allowed
gemma_3_12b,Google,,12000000000.0,extracted_from_name,1.73e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 4.07e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 12,000,000,000 params × 240,000,000,000 tokens = 1.73e+22 FLOP (Modern model: 12B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.794507,,
baichuan2_13b,Unknown,,13000000000.0,extracted_from_name,1.62e+22,medium,Known parameters with estimated training tokens,scaling_laws,,high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 13,000,000,000 params × 208,000,000,000 tokens = 1.62e+22 FLOP (Chinese model: 13B params * 16 tokens/param)",https://llmbench.github.io/ChineseSimpleQA/ (ChineseSimpleQA - Question answering benchmark for Chinese LLMs),,2025-08-04T16:03:15.478266,,allowed
alpaca_13b,Stanford,,13000000000.0,extracted_from_name,1.52e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 1.93e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 13,000,000,000 params × 195,000,000,000 tokens = 1.52e+22 FLOP (Generic estimate: 13B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.075239,,allowed
gpt4all_13b_snoozy,Nomic AI,,13000000000.0,extracted_from_name,1.52e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 1.95e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 13,000,000,000 params × 195,000,000,000 tokens = 1.52e+22 FLOP (Generic estimate: 13B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.075179,,allowed
koala_13b,UC Berkeley,,13000000000.0,extracted_from_name,1.52e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 1.97e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 13,000,000,000 params × 195,000,000,000 tokens = 1.52e+22 FLOP (Generic estimate: 13B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.075119,,allowed
vicuna_13b,LMSYS,,13000000000.0,extracted_from_name,1.52e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.40e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 13,000,000,000 params × 195,000,000,000 tokens = 1.52e+22 FLOP (Generic estimate: 13B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.073328,,allowed
wizardlm_13b,Microsoft,,13000000000.0,extracted_from_name,1.52e+22,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 2.14e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 13,000,000,000 params × 195,000,000,000 tokens = 1.52e+22 FLOP (Generic estimate: 13B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.815515,,
llama_3.2_11b_vision,Meta,,11000000000.0,extracted_from_name,1.45e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 8.04e+24 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 11,000,000,000 params × 220,000,000,000 tokens = 1.45e+22 FLOP (Modern model: 11B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.089977,,allowed
dolly_v2_12b,Databricks,,12000000000.0,extracted_from_name,1.30e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 1.48e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 12,000,000,000 params × 180,000,000,000 tokens = 1.30e+22 FLOP (Generic estimate: 12B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.075869,,allowed
oasst_pythia_12b,OpenAssistant,,12000000000.0,extracted_from_name,1.30e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 1.70e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 12,000,000,000 params × 180,000,000,000 tokens = 1.30e+22 FLOP (Generic estimate: 12B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.075659,,allowed
pixtral_12b,Mistral,,12000000000.0,extracted_from_name,1.30e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 7.78e+24 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 12,000,000,000 params × 180,000,000,000 tokens = 1.30e+22 FLOP (Generic estimate: 12B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.089659,,allowed
solar_10.7b_instruct,Upstage AI,,10700000000.0,extracted_from_name,1.24e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.23e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 10,700,000,000 params × 192,600,000,000 tokens = 1.24e+22 FLOP (Specialized model: 11B params * 18 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.814630,,
llama_2_13b,Meta,,13000000000.0,extracted_from_name,1.22e+22,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 1.38e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 13,000,000,000 params × 156,000,000,000 tokens = 1.22e+22 FLOP (Mid-era model: 13B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.073159,,allowed
yi_coder_9b,01 AI,,9000000000.0,extracted_from_name,8.75e+21,medium,Known parameters with estimated training tokens,scaling_laws,,high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 9,000,000,000 params × 162,000,000,000 tokens = 8.75e+21 FLOP (Specialized model: 9B params * 18 tokens/param)",https://github.com/openai/open-agent-leaderboard (Open Agent Leaderboard - Multi-task agent performance evaluation),,2025-08-04T16:03:15.513596,,allowed
llama_13b,Meta,,13000000000.0,extracted_from_name,8.11e+21,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 1.49e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 13,000,000,000 params × 104,000,000,000 tokens = 8.11e+21 FLOP (Early era model: 13B params * 8 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.075815,,allowed
llama_3.1_tulu_3_8b,Ai2,,8000000000.0,extracted_from_name,7.68e+21,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 3.04e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 8,000,000,000 params × 160,000,000,000 tokens = 7.68e+21 FLOP (Modern model: 8B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.808948,,
gemma_2_9b,Google,,9000000000.0,extracted_from_name,5.83e+21,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 3.09e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 9,000,000,000 params × 108,000,000,000 tokens = 5.83e+21 FLOP (Mid-era model: 9B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.807089,,
gemma_2_9b_it_simpo,Princeton,,9000000000.0,extracted_from_name,5.83e+21,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 3.21e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 9,000,000,000 params × 108,000,000,000 tokens = 5.83e+21 FLOP (Mid-era model: 9B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.802981,,
aya_expanse_8b,Cohere,,8000000000.0,extracted_from_name,5.76e+21,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 2.97e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 8,000,000,000 params × 120,000,000,000 tokens = 5.76e+21 FLOP (Generic estimate: 8B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.822242,,
c4ai_aya_expanse_8b,Cohere,,8000000000.0,extracted_from_name,5.76e+21,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.93e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 8,000,000,000 params × 120,000,000,000 tokens = 5.76e+21 FLOP (Generic estimate: 8B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.063908,,allowed
gemini_1.5_flash_8b_001,Google,,8000000000.0,extracted_from_name,5.76e+21,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.35e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 8,000,000,000 params × 120,000,000,000 tokens = 5.76e+21 FLOP (Generic estimate: 8B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.061838,,allowed
granite_3.0_8b,IBM,,8000000000.0,extracted_from_name,5.76e+21,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 2.42e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 8,000,000,000 params × 120,000,000,000 tokens = 5.76e+21 FLOP (Generic estimate: 8B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.810609,,
granite_3.1_8b,IBM,,8000000000.0,extracted_from_name,5.76e+21,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 2.85e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 8,000,000,000 params × 120,000,000,000 tokens = 5.76e+21 FLOP (Generic estimate: 8B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.809599,,
ministral_8b,Mistral,,8000000000.0,extracted_from_name,5.76e+21,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 3.11e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 8,000,000,000 params × 120,000,000,000 tokens = 5.76e+21 FLOP (Generic estimate: 8B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.808263,,
mixtral_8x7b_instruct,Mistral,,7000000000.0,extracted_from_name,5.29e+21,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 1.50e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 126,000,000,000 tokens = 5.29e+21 FLOP (Specialized model: 7B params * 18 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.069036,,allowed
qwen1.5_7b,Alibaba,,7000000000.0,extracted_from_name,4.70e+21,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.34e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 112,000,000,000 tokens = 4.70e+21 FLOP (Chinese model: 7B params * 16 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.073254,,allowed
gemma_1.1_7b,Google,,7000000000.0,extracted_from_name,4.41e+21,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 2.37e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.813290,,
gemma_7b,Google,,7000000000.0,extracted_from_name,4.41e+21,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.36e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.073736,,allowed
molmo_7b_d,Ai2,,7000000000.0,extracted_from_name,4.41e+21,low,Extracted parameters with uncertain training tokens,scaling_laws,,high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.823516,,
mpt_7b,MosaicML,,7000000000.0,extracted_from_name,4.41e+21,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 1.92e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.075299,,allowed
nous_hermes_2_mixtral_8x7b_dpo,NousResearch,,7000000000.0,extracted_from_name,4.41e+21,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 2.41e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.814107,,
olmo_7b,Allen AI,,7000000000.0,extracted_from_name,4.41e+21,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.02e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.075058,,allowed
stablelm_tuned_alpha_7b,Stability AI,,7000000000.0,extracted_from_name,4.41e+21,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 1.40e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.075944,,allowed
starling_lm_7b,Nexusflow,,7000000000.0,extracted_from_name,4.41e+21,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 2.64e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.813886,,
starling_lm_7b_alpha,UC Berkeley,,7000000000.0,extracted_from_name,4.41e+21,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 2.40e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.814465,,
stripedhyena_nous_7b,Together AI,,7000000000.0,extracted_from_name,4.41e+21,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.27e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.074473,,allowed
vicuna_7b,LMSYS,,7000000000.0,extracted_from_name,4.41e+21,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.24e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.074544,,allowed
zephyr_7b,HuggingFace,,7000000000.0,extracted_from_name,4.41e+21,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 2.13e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.817921,,
zephyr_7b_alpha,HuggingFace,,7000000000.0,extracted_from_name,4.41e+21,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.32e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.073924,,allowed
chatglm2_6b,Tsinghua,,6000000000.0,extracted_from_name,3.89e+21,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 1.76e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 6,000,000,000 params × 108,000,000,000 tokens = 3.89e+21 FLOP (Specialized model: 6B params * 18 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.075612,,allowed
chatglm3_6b,Tsinghua,,6000000000.0,extracted_from_name,3.89e+21,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 1.88e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 6,000,000,000 params × 108,000,000,000 tokens = 3.89e+21 FLOP (Specialized model: 6B params * 18 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.075471,,allowed
chatglm_6b,Tsinghua,,6000000000.0,extracted_from_name,3.89e+21,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 1.62e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 6,000,000,000 params × 108,000,000,000 tokens = 3.89e+21 FLOP (Specialized model: 6B params * 18 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.075700,,allowed
dolphin_2.2.1_mistral_7b,Cognitive,,7000000000.0,extracted_from_name,3.53e+21,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.15e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 84,000,000,000 tokens = 3.53e+21 FLOP (Mid-era model: 7B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.814908,,
mistral_7b,Mistral,,7000000000.0,extracted_from_name,3.53e+21,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.21e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 84,000,000,000 tokens = 3.53e+21 FLOP (Mid-era model: 7B params * 12 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.074754,,allowed
mistral_7b_instruct,Mistral,,7000000000.0,extracted_from_name,3.53e+21,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 1.22e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 84,000,000,000 tokens = 3.53e+21 FLOP (Mid-era model: 7B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.072559,,allowed
openhermes_2.5_mistral_7b,NousResearch,,7000000000.0,extracted_from_name,3.53e+21,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.29e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 84,000,000,000 tokens = 3.53e+21 FLOP (Mid-era model: 7B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.812692,,
qwen2_vl_7b,Alibaba,,7000000000.0,extracted_from_name,3.53e+21,medium,Known parameters with estimated training tokens,scaling_laws,,high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 84,000,000,000 tokens = 3.53e+21 FLOP (Mid-era model: 7B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.089904,,allowed
gemma_3_4b,Google,,4000000000.0,extracted_from_name,1.92e+21,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 3.69e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 4,000,000,000 params × 80,000,000,000 tokens = 1.92e+21 FLOP (Modern model: 4B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.801257,,
gemma_3n_e4b,Google,,4000000000.0,extracted_from_name,1.92e+21,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 3.87e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 4,000,000,000 params × 80,000,000,000 tokens = 1.92e+21 FLOP (Modern model: 4B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.799367,,
qwen1.5_4b,Alibaba,,4000000000.0,extracted_from_name,1.54e+21,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.07e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 4,000,000,000 params × 64,000,000,000 tokens = 1.54e+21 FLOP (Chinese model: 4B params * 16 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.074998,,allowed
llama_3.2_3b,Meta,,3000000000.0,extracted_from_name,1.08e+21,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 1.37e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 3,000,000,000 params × 60,000,000,000 tokens = 1.08e+21 FLOP (Modern model: 3B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.071909,,allowed
fastchat_t5_3b,LMSYS,,3000000000.0,extracted_from_name,9.72e+20,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 1.57e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 3,000,000,000 params × 54,000,000,000 tokens = 9.72e+20 FLOP (Specialized model: 3B params * 18 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.075759,,allowed
gemma_1.1_2b,Google,,2000000000.0,extracted_from_name,3.60e+20,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.20e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 2,000,000,000 params × 30,000,000,000 tokens = 3.60e+20 FLOP (Generic estimate: 2B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.074879,,allowed
granite_3.0_2b,IBM,,2000000000.0,extracted_from_name,3.6e+20,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 2.33e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 2,000,000,000 params × 30,000,000,000 tokens = 3.60e+20 FLOP (Generic estimate: 2B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.815024,,
granite_3.1_2b,IBM,,2000000000.0,extracted_from_name,3.6e+20,low,Extracted parameters with uncertain training tokens,scaling_laws,Benchmark Based: 2.68e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 2,000,000,000 params × 30,000,000,000 tokens = 3.60e+20 FLOP (Generic estimate: 2B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.812294,,
gemma_2_2b,Google,,2000000000.0,extracted_from_name,2.88e+20,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.66e+25 (Medium),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 2,000,000,000 params × 24,000,000,000 tokens = 2.88e+20 FLOP (Mid-era model: 2B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.810154,,
gemma_2b,Google,,2000000000.0,extracted_from_name,2.88e+20,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.08e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 2,000,000,000 params × 24,000,000,000 tokens = 2.88e+20 FLOP (Mid-era model: 2B params * 12 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.074938,,allowed
smollm2_1.7b,HuggingFace,,1700000000.0,extracted_from_name,2.60e+20,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 2.32e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 1,700,000,000 params × 25,500,000,000 tokens = 2.60e+20 FLOP (Generic estimate: 2B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T20:32:45.073862,,allowed
llama_3.2_1b,Meta,,1000000000.0,extracted_from_name,1.20e+20,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 1.10e+25 (Low),high_confidence_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 1,000,000,000 params × 20,000,000,000 tokens = 1.20e+20 FLOP (Modern model: 1B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T20:32:45.074683,,allowed
