model,developer,release_date,parameters,training_flop,confidence,estimation_method,alternative_methods,threshold_classification,status,reasoning,sources,verified,last_updated,notes
llama_3.1_70b,Meta,,70000000000,6.30e+24,high,scaling_laws,Benchmark Based: 2.81e+25 (Medium),high_confidence_below_1e25,confirmed_below_1e25,"Scaling laws with documented parameters: Chinchilla scaling law: 6 × 70,000,000,000 params × 15,000,000,000,000 tokens = 6.30e+24 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.889360,
llama_3_70b,Meta,,70000000000,6.30e+24,high,scaling_laws,Benchmark Based: 2.55e+25 (Medium),high_confidence_below_1e25,confirmed_below_1e25,"Scaling laws with documented parameters: Chinchilla scaling law: 6 × 70,000,000,000 params × 15,000,000,000,000 tokens = 6.30e+24 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.890669,
llama_3.1_nemotron_ultra_253b,Nvidia,,253000000000,5.76e+24,medium,scaling_laws,Benchmark Based: 4.00e+25 (Medium),high_confidence_below_1e25,likely_above_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 253,000,000,000 params × 3,795,000,000,000 tokens = 5.76e+24 FLOP (Modern large model: 253B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.884089,
deepseek_r1,DeepSeek,,671000000000,3.00e+24,high,epoch_estimate,Scaling Laws: 5.96e+25 (Medium); Benchmark Based: 4.49e+25 (Medium),high_confidence_below_1e25,confirmed_below_1e25,https://epoch.ai/gradient-updates/what-went-into-training-deepseek-r1,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.881997,
falcon_180b,TII,,180000000000,2.92e+24,low,scaling_laws,Benchmark Based: 1.68e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 180,000,000,000 params × 2,700,000,000,000 tokens = 2.92e+24 FLOP (Generic estimate: 180B params * 15 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.896245,
zephyr_orpo_141b,HuggingFace,,141000000000,1.79e+24,low,scaling_laws,Benchmark Based: 1.71e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 141,000,000,000 params × 2,115,000,000,000 tokens = 1.79e+24 FLOP (Generic estimate: 141B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.893577,
qwen1.5_110b,Alibaba,,110000000000,1.16e+24,medium,scaling_laws,Benchmark Based: 2.05e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 110,000,000,000 params × 1,760,000,000,000 tokens = 1.16e+24 FLOP (Chinese model: 110B params * 16 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.892606,
llama_3.2_90b_vision,Meta,,90000000000,9.72e+23,medium,scaling_laws,,high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 90,000,000,000 params × 1,800,000,000,000 tokens = 9.72e+23 FLOP (Modern model: 90B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.905009,
llama_2_70b,Meta,,70000000000,8.40e+23,high,scaling_laws,Benchmark Based: 1.07e+25 (Medium),high_confidence_below_1e25,confirmed_below_1e25,"Scaling laws with documented parameters: Chinchilla scaling law: 6 × 70,000,000,000 params × 2,000,000,000,000 tokens = 8.40e+23 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.895599,
llama_3.1_8b,Meta,,8000000000,7.20e+23,high,scaling_laws,Benchmark Based: 2.12e+25 (Medium),high_confidence_below_1e25,confirmed_below_1e25,"Scaling laws with documented parameters: Chinchilla scaling law: 6 × 8,000,000,000 params × 15,000,000,000,000 tokens = 7.20e+23 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.893771,
llama_3_8b,Meta,,8000000000,7.20e+23,high,scaling_laws,Benchmark Based: 1.80e+25 (Medium),high_confidence_below_1e25,confirmed_below_1e25,"Scaling laws with documented parameters: Chinchilla scaling law: 6 × 8,000,000,000 params × 15,000,000,000,000 tokens = 7.20e+23 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.893498,
llama_3.1_nemotron_70b,Nvidia,,70000000000,5.88e+23,medium,scaling_laws,Benchmark Based: 3.68e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,400,000,000,000 tokens = 5.88e+23 FLOP (Modern model: 70B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.889122,
llama_3.1_tulu_3_70b,Ai2,,70000000000,5.88e+23,medium,scaling_laws,Benchmark Based: 2.78e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,400,000,000,000 tokens = 5.88e+23 FLOP (Modern model: 70B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.889321,
llama_3.3_70b,Meta,,70000000000,5.88e+23,medium,scaling_laws,Benchmark Based: 3.59e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,400,000,000,000 tokens = 5.88e+23 FLOP (Modern model: 70B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.887473,
athene_v2_chat_72b,NexusFlow,,72000000000,5.60e+23,medium,scaling_laws,Benchmark Based: 3.77e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 72,000,000,000 params × 1,296,000,000,000 tokens = 5.60e+23 FLOP (Specialized model: 72B params * 18 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.899962,
codellama_70b,Meta,,70000000000,5.29e+23,medium,scaling_laws,Benchmark Based: 1.62e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,260,000,000,000 tokens = 5.29e+23 FLOP (Specialized model: 70B params * 18 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.897023,
qwen1.5_72b,Alibaba,,72000000000,4.98e+23,medium,scaling_laws,Benchmark Based: 1.81e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 72,000,000,000 params × 1,152,000,000,000 tokens = 4.98e+23 FLOP (Chinese model: 72B params * 16 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.892677,
molmo_72b,Ai2,,72000000000,4.67e+23,low,scaling_laws,,high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 72,000,000,000 params × 1,080,000,000,000 tokens = 4.67e+23 FLOP (Generic estimate: 72B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.904900,
athene_70b,NexusFlow,,70000000000,4.41e+23,low,scaling_laws,Benchmark Based: 2.83e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,050,000,000,000 tokens = 4.41e+23 FLOP (Generic estimate: 70B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.889020,
llama2_70b_steerlm,Nvidia,,70000000000,4.41e+23,low,scaling_laws,Benchmark Based: 1.76e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,050,000,000,000 tokens = 4.41e+23 FLOP (Generic estimate: 70B params * 15 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.895923,
nv_llama2_70b_steerlm,Nvidia,,70000000000,4.41e+23,low,scaling_laws,Benchmark Based: 1.02e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,050,000,000,000 tokens = 4.41e+23 FLOP (Generic estimate: 70B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.903286,
pplx_70b_online,Perplexity AI,,70000000000,4.41e+23,low,scaling_laws,Benchmark Based: 9.95e+24 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,050,000,000,000 tokens = 4.41e+23 FLOP (Generic estimate: 70B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.903871,
tulu_2_dpo_70b,Ai2,,70000000000,4.41e+23,low,scaling_laws,Benchmark Based: 1.61e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,050,000,000,000 tokens = 4.41e+23 FLOP (Generic estimate: 70B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.895028,
wizardlm_70b,Microsoft,,70000000000,4.41e+23,low,scaling_laws,Benchmark Based: 1.60e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,050,000,000,000 tokens = 4.41e+23 FLOP (Generic estimate: 70B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.894514,
qwen2.5_72b,Alibaba,,72000000000,3.73e+23,medium,scaling_laws,Benchmark Based: 2.86e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 72,000,000,000 params × 864,000,000,000 tokens = 3.73e+23 FLOP (Mid-era model: 72B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.889079,
qwen2.5_vl_72b,Alibaba,,72000000000,3.73e+23,medium,scaling_laws,,high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 72,000,000,000 params × 864,000,000,000 tokens = 3.73e+23 FLOP (Mid-era model: 72B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.904720,
qwen2_72b,Alibaba,,72000000000,3.73e+23,medium,scaling_laws,Benchmark Based: 2.21e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 72,000,000,000 params × 864,000,000,000 tokens = 3.73e+23 FLOP (Mid-era model: 72B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.891176,
qwen2_vl_72b,Alibaba,,72000000000,3.73e+23,medium,scaling_laws,,high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 72,000,000,000 params × 864,000,000,000 tokens = 3.73e+23 FLOP (Mid-era model: 72B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.904836,
llama_3.1_nemotron_51b,Nvidia,,51000000000,3.12e+23,medium,scaling_laws,Benchmark Based: 2.60e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 51,000,000,000 params × 1,020,000,000,000 tokens = 3.12e+23 FLOP (Modern model: 51B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.889401,
llama_3.3_nemotron_49b_super,Nvidia,,49000000000,2.88e+23,medium,scaling_laws,Benchmark Based: 4.02e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 49,000,000,000 params × 980,000,000,000 tokens = 2.88e+23 FLOP (Modern model: 49B params * 20 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.886543,
llama_3.3_nemotron_super_49b,Nvidia,,49000000000,2.88e+23,medium,scaling_laws,Benchmark Based: 3.90e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 49,000,000,000 params × 980,000,000,000 tokens = 2.88e+23 FLOP (Modern model: 49B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.899512,
codellama_34b,Meta,,34000000000,1.39e+23,medium,scaling_laws,Benchmark Based: 9.39e+24 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 34,000,000,000 params × 680,000,000,000 tokens = 1.39e+23 FLOP (Modern model: 34B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.896744,
qwen3_32b,Alibaba,,32000000000,1.23e+23,medium,scaling_laws,Benchmark Based: 4.16e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 640,000,000,000 tokens = 1.23e+23 FLOP (Modern model: 32B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.884649,
yi_1.5_34b,01 AI,,34000000000,1.11e+23,medium,scaling_laws,Benchmark Based: 2.04e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 34,000,000,000 params × 544,000,000,000 tokens = 1.11e+23 FLOP (Chinese model: 34B params * 16 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.893642,
yi_34b,01 AI,,34000000000,1.11e+23,medium,scaling_laws,Benchmark Based: 1.63e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 34,000,000,000 params × 544,000,000,000 tokens = 1.11e+23 FLOP (Chinese model: 34B params * 16 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.894796,
qwen3_30b,Alibaba,,30000000000,1.08e+23,medium,scaling_laws,Benchmark Based: 4.01e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 30,000,000,000 params × 600,000,000,000 tokens = 1.08e+23 FLOP (Modern model: 30B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.886384,
qwen1.5_32b,Alibaba,,32000000000,9.83e+22,medium,scaling_laws,Benchmark Based: 1.68e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 512,000,000,000 tokens = 9.83e+22 FLOP (Chinese model: 32B params * 16 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.893843,
guanaco_33b,UW,,33000000000,9.80e+22,low,scaling_laws,Benchmark Based: 1.61e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 33,000,000,000 params × 495,000,000,000 tokens = 9.80e+22 FLOP (Generic estimate: 33B params * 15 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.897364,
vicuna_33b,LMSYS,,33000000000,9.80e+22,low,scaling_laws,Benchmark Based: 1.04e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 33,000,000,000 params × 495,000,000,000 tokens = 9.80e+22 FLOP (Generic estimate: 33B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.895365,
aya_expanse_32b,Cohere,,32000000000,9.22e+22,low,scaling_laws,Benchmark Based: 2.58e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 480,000,000,000 tokens = 9.22e+22 FLOP (Generic estimate: 32B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.900653,
aya_vision_32b,Cohere,,32000000000,9.22e+22,low,scaling_laws,,high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 480,000,000,000 tokens = 9.22e+22 FLOP (Generic estimate: 32B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.905050,
c4ai_aya_expanse_32b,Cohere,,32000000000,9.22e+22,low,scaling_laws,Benchmark Based: 2.83e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 480,000,000,000 tokens = 9.22e+22 FLOP (Generic estimate: 32B params * 15 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.891020,
olmo_2_32b,Ai2,,32000000000,9.22e+22,low,scaling_laws,Benchmark Based: 2.56e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 480,000,000,000 tokens = 9.22e+22 FLOP (Generic estimate: 32B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.891107,
qwq_32b,Alibaba,,32000000000,9.22e+22,low,scaling_laws,Benchmark Based: 4.09e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 480,000,000,000 tokens = 9.22e+22 FLOP (Generic estimate: 32B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.885065,
qwq_32b_preview,Alibaba,,32000000000,9.22e+22,low,scaling_laws,Benchmark Based: 1.81e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 480,000,000,000 tokens = 9.22e+22 FLOP (Generic estimate: 32B params * 15 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.895743,
gemma_3_27b,Google,,27000000000,8.75e+22,medium,scaling_laws,Benchmark Based: 4.32e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 27,000,000,000 params × 540,000,000,000 tokens = 8.75e+22 FLOP (Modern model: 27B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.883949,
llama_2_7b,Meta,,7000000000,8.40e+22,high,scaling_laws,Benchmark Based: 1.04e+25 (Medium),high_confidence_below_1e25,confirmed_below_1e25,"Scaling laws with documented parameters: Chinchilla scaling law: 6 × 7,000,000,000 params × 2,000,000,000,000 tokens = 8.40e+22 FLOP",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.897624,
mpt_30b,MosaicML,,30000000000,8.10e+22,low,scaling_laws,Benchmark Based: 9.41e+24 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 30,000,000,000 params × 450,000,000,000 tokens = 8.10e+22 FLOP (Generic estimate: 30B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.896137,
qwen2.5_coder_32b,Alibaba,,32000000000,7.37e+22,medium,scaling_laws,Benchmark Based: 2.61e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 384,000,000,000 tokens = 7.37e+22 FLOP (Mid-era model: 32B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.890822,
qwen2.5_vl_32b,Alibaba,,32000000000,7.37e+22,medium,scaling_laws,,high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 384,000,000,000 tokens = 7.37e+22 FLOP (Mid-era model: 32B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.904395,
internvl2_26b,OpenGVLab,,26000000000,6.08e+22,low,scaling_laws,,high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 26,000,000,000 params × 390,000,000,000 tokens = 6.08e+22 FLOP (Generic estimate: 26B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.904979,
gemma_2_27b,Google,,27000000000,5.25e+22,medium,scaling_laws,Benchmark Based: 2.62e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 27,000,000,000 params × 324,000,000,000 tokens = 5.25e+22 FLOP (Mid-era model: 27B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.889845,
mixtral_8x22b_instruct,Mistral,,22000000000,5.23e+22,medium,scaling_laws,Benchmark Based: 1.79e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 22,000,000,000 params × 396,000,000,000 tokens = 5.23e+22 FLOP (Specialized model: 22B params * 18 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.892967,
mistral_small_24b,Mistral,,24000000000,4.15e+22,medium,scaling_laws,Benchmark Based: 2.63e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 24,000,000,000 params × 288,000,000,000 tokens = 4.15e+22 FLOP (Mid-era model: 24B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.890754,
mistral_small_3.1_24b,Mistral,,24000000000,4.15e+22,medium,scaling_laws,Benchmark Based: 2.83e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 24,000,000,000 params × 288,000,000,000 tokens = 4.15e+22 FLOP (Mid-era model: 24B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.889277,
reka_flash_21b,Reka AI,,21000000000,3.97e+22,low,scaling_laws,Benchmark Based: 2.57e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 21,000,000,000 params × 315,000,000,000 tokens = 3.97e+22 FLOP (Generic estimate: 21B params * 15 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.893131,
reka_flash_21b_online,Reka AI,,21000000000,3.97e+22,low,scaling_laws,Benchmark Based: 2.60e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 21,000,000,000 params × 315,000,000,000 tokens = 3.97e+22 FLOP (Generic estimate: 21B params * 15 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.892763,
internlm2.5_20b,InternLM,,20000000000,3.60e+22,low,scaling_laws,Benchmark Based: 1.79e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 20,000,000,000 params × 300,000,000,000 tokens = 3.60e+22 FLOP (Generic estimate: 20B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.901009,
internlm2_5_20b,InternLM,,20000000000,3.60e+22,low,scaling_laws,Benchmark Based: 2.15e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 20,000,000,000 params × 300,000,000,000 tokens = 3.60e+22 FLOP (Generic estimate: 20B params * 15 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.894176,
llama_4_maverick_17b_128e,Meta,,17000000000,3.47e+22,medium,scaling_laws,Benchmark Based: 3.73e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 17,000,000,000 params × 340,000,000,000 tokens = 3.47e+22 FLOP (Modern model: 17B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.886449,
llama_4_scout_17b_16e,Meta,,17000000000,3.47e+22,medium,scaling_laws,Benchmark Based: 3.61e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 17,000,000,000 params × 340,000,000,000 tokens = 3.47e+22 FLOP (Modern model: 17B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.887296,
qwen1.5_14b,Alibaba,,14000000000,1.88e+22,medium,scaling_laws,Benchmark Based: 1.65e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 14,000,000,000 params × 224,000,000,000 tokens = 1.88e+22 FLOP (Chinese model: 14B params * 16 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.894244,
qwen_14b,Alibaba,,14000000000,1.88e+22,medium,scaling_laws,Benchmark Based: 1.66e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 14,000,000,000 params × 224,000,000,000 tokens = 1.88e+22 FLOP (Chinese model: 14B params * 16 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.896904,
rwkv_4_raven_14b,RWKV,,14000000000,1.76e+22,low,scaling_laws,Benchmark Based: 4.91e+24 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 14,000,000,000 params × 210,000,000,000 tokens = 1.76e+22 FLOP (Generic estimate: 14B params * 15 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.898168,
gemma_3_12b,Google,,12000000000,1.73e+22,medium,scaling_laws,Benchmark Based: 4.10e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 12,000,000,000 params × 240,000,000,000 tokens = 1.73e+22 FLOP (Modern model: 12B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.884856,
alpaca_13b,Stanford,,13000000000,1.52e+22,low,scaling_laws,Benchmark Based: 5.23e+24 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 13,000,000,000 params × 195,000,000,000 tokens = 1.52e+22 FLOP (Generic estimate: 13B params * 15 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.897999,
gpt4all_13b_snoozy,Nomic AI,,13000000000,1.52e+22,low,scaling_laws,Benchmark Based: 5.26e+24 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 13,000,000,000 params × 195,000,000,000 tokens = 1.52e+22 FLOP (Generic estimate: 13B params * 15 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.897948,
koala_13b,UC Berkeley,,13000000000,1.52e+22,low,scaling_laws,Benchmark Based: 5.32e+24 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 13,000,000,000 params × 195,000,000,000 tokens = 1.52e+22 FLOP (Generic estimate: 13B params * 15 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.897894,
vicuna_13b,LMSYS,,13000000000,1.52e+22,low,scaling_laws,Benchmark Based: 1.68e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 13,000,000,000 params × 195,000,000,000 tokens = 1.52e+22 FLOP (Generic estimate: 13B params * 15 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.896692,
wizardlm_13b,Microsoft,,13000000000,1.52e+22,low,scaling_laws,Benchmark Based: 9.60e+24 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 13,000,000,000 params × 195,000,000,000 tokens = 1.52e+22 FLOP (Generic estimate: 13B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.896299,
llama_3.2_11b_vision,Meta,,11000000000,1.45e+22,medium,scaling_laws,,high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 11,000,000,000 params × 220,000,000,000 tokens = 1.45e+22 FLOP (Modern model: 11B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.905114,
dolly_v2_12b,Databricks,,12000000000,1.30e+22,low,scaling_laws,Benchmark Based: 9.30e+23 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 12,000,000,000 params × 180,000,000,000 tokens = 1.30e+22 FLOP (Generic estimate: 12B params * 15 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.898520,
oasst_pythia_12b,OpenAssistant,,12000000000,1.30e+22,low,scaling_laws,Benchmark Based: 1.06e+24 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 12,000,000,000 params × 180,000,000,000 tokens = 1.30e+22 FLOP (Generic estimate: 12B params * 15 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.898280,
pixtral_12b,Mistral,,12000000000,1.30e+22,low,scaling_laws,,high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 12,000,000,000 params × 180,000,000,000 tokens = 1.30e+22 FLOP (Generic estimate: 12B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.904944,
solar_10.7b_instruct,Upstage AI,,10700000000,1.24e+22,medium,scaling_laws,Benchmark Based: 9.92e+24 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 10,700,000,000 params × 192,600,000,000 tokens = 1.24e+22 FLOP (Specialized model: 11B params * 18 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.895981,
llama_2_13b,Meta,,13000000000,1.22e+22,medium,scaling_laws,Benchmark Based: 9.84e+24 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 13,000,000,000 params × 156,000,000,000 tokens = 1.22e+22 FLOP (Mid-era model: 13B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.896567,
llama_13b,Meta,,13000000000,8.11e+21,low,scaling_laws,Benchmark Based: 9.35e+23 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 13,000,000,000 params × 104,000,000,000 tokens = 8.11e+21 FLOP (Early era model: 13B params * 8 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.898438,
llama_3.1_tulu_3_8b,Ai2,,8000000000,7.68e+21,medium,scaling_laws,Benchmark Based: 2.16e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 8,000,000,000 params × 160,000,000,000 tokens = 7.68e+21 FLOP (Modern model: 8B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.893197,
gemma_2_9b,Google,,9000000000,5.83e+21,medium,scaling_laws,Benchmark Based: 2.23e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 9,000,000,000 params × 108,000,000,000 tokens = 5.83e+21 FLOP (Mid-era model: 9B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.891460,
gemma_2_9b_it_simpo,Princeton,,9000000000,5.83e+21,medium,scaling_laws,Benchmark Based: 2.61e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 9,000,000,000 params × 108,000,000,000 tokens = 5.83e+21 FLOP (Mid-era model: 9B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.889991,
aya_expanse_8b,Cohere,,8000000000,5.76e+21,low,scaling_laws,Benchmark Based: 2.10e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 8,000,000,000 params × 120,000,000,000 tokens = 5.76e+21 FLOP (Generic estimate: 8B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.900732,
c4ai_aya_expanse_8b,Cohere,,8000000000,5.76e+21,low,scaling_laws,Benchmark Based: 2.28e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 8,000,000,000 params × 120,000,000,000 tokens = 5.76e+21 FLOP (Generic estimate: 8B params * 15 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.893441,
gemini_1.5_flash_8b_001,Google,,8000000000,5.76e+21,low,scaling_laws,Benchmark Based: 2.59e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 8,000,000,000 params × 120,000,000,000 tokens = 5.76e+21 FLOP (Generic estimate: 8B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.891834,
granite_3.0_8b,IBM,,8000000000,5.76e+21,low,scaling_laws,Benchmark Based: 1.02e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 8,000,000,000 params × 120,000,000,000 tokens = 5.76e+21 FLOP (Generic estimate: 8B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.894584,
granite_3.1_8b,IBM,,8000000000,5.76e+21,low,scaling_laws,Benchmark Based: 1.74e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 8,000,000,000 params × 120,000,000,000 tokens = 5.76e+21 FLOP (Generic estimate: 8B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.893705,
ministral_8b,Mistral,,8000000000,5.76e+21,low,scaling_laws,Benchmark Based: 2.14e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 8,000,000,000 params × 120,000,000,000 tokens = 5.76e+21 FLOP (Generic estimate: 8B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.892521,
mixtral_8x7b_instruct,Mistral,,7000000000,5.29e+21,medium,scaling_laws,Benchmark Based: 1.66e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 126,000,000,000 tokens = 5.29e+21 FLOP (Specialized model: 7B params * 18 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.894035,
qwen1.5_7b,Alibaba,,7000000000,4.70e+21,medium,scaling_laws,Benchmark Based: 9.73e+24 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 112,000,000,000 tokens = 4.70e+21 FLOP (Chinese model: 7B params * 16 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.896636,
gemma_1.1_7b,Google,,7000000000,4.41e+21,low,scaling_laws,Benchmark Based: 1.01e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.895307,
gemma_7b,Google,,7000000000,4.41e+21,low,scaling_laws,Benchmark Based: 1.65e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.896959,
mpt_7b,MosaicML,,7000000000,4.41e+21,low,scaling_laws,Benchmark Based: 5.19e+24 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.898052,
nous_hermes_2_mixtral_8x7b_dpo,NousResearch,,7000000000,4.41e+21,low,scaling_laws,Benchmark Based: 1.59e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.895671,
olmo_7b,Allen AI,,7000000000,4.41e+21,low,scaling_laws,Benchmark Based: 9.52e+24 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.897839,
stablelm_tuned_alpha_7b,Stability AI,,7000000000,4.41e+21,low,scaling_laws,Benchmark Based: 8.74e+23 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.898590,
starling_lm_7b,Nexusflow,,7000000000,4.41e+21,low,scaling_laws,Benchmark Based: 1.65e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.895546,
starling_lm_7b_alpha,UC Berkeley,,7000000000,4.41e+21,low,scaling_laws,Benchmark Based: 1.04e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.895862,
stripedhyena_nous_7b,Together AI,,7000000000,4.41e+21,low,scaling_laws,Benchmark Based: 1.07e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.897417,
vicuna_7b,LMSYS,,7000000000,4.41e+21,low,scaling_laws,Benchmark Based: 1.05e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.897467,
zephyr_7b,HuggingFace,,7000000000,4.41e+21,low,scaling_laws,Benchmark Based: 1.64e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.897273,
zephyr_7b_alpha,HuggingFace,,7000000000,4.41e+21,low,scaling_laws,Benchmark Based: 1.62e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.897131,
chatglm2_6b,Tsinghua,,6000000000,3.89e+21,medium,scaling_laws,Benchmark Based: 4.76e+24 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 6,000,000,000 params × 108,000,000,000 tokens = 3.89e+21 FLOP (Specialized model: 6B params * 18 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.898221,
chatglm3_6b,Tsinghua,,6000000000,3.89e+21,medium,scaling_laws,Benchmark Based: 5.07e+24 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 6,000,000,000 params × 108,000,000,000 tokens = 3.89e+21 FLOP (Specialized model: 6B params * 18 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.898115,
chatglm_6b,Tsinghua,,6000000000,3.89e+21,medium,scaling_laws,Benchmark Based: 1.01e+24 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 6,000,000,000 params × 108,000,000,000 tokens = 3.89e+21 FLOP (Specialized model: 6B params * 18 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.898333,
dolphin_2.2.1_mistral_7b,Cognitive,,7000000000,3.53e+21,medium,scaling_laws,Benchmark Based: 9.70e+24 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 84,000,000,000 tokens = 3.53e+21 FLOP (Mid-era model: 7B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.896035,
mistral_7b,Mistral,,7000000000,3.53e+21,medium,scaling_laws,Benchmark Based: 1.04e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 84,000,000,000 tokens = 3.53e+21 FLOP (Mid-era model: 7B params * 12 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.897574,
mistral_7b_instruct,Mistral,,7000000000,3.53e+21,medium,scaling_laws,Benchmark Based: 9.97e+24 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 84,000,000,000 tokens = 3.53e+21 FLOP (Mid-era model: 7B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.896190,
openhermes_2.5_mistral_7b,NousResearch,,7000000000,3.53e+21,medium,scaling_laws,Benchmark Based: 1.01e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 84,000,000,000 tokens = 3.53e+21 FLOP (Mid-era model: 7B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.895089,
qwen2_vl_7b,Alibaba,,7000000000,3.53e+21,medium,scaling_laws,,high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 84,000,000,000 tokens = 3.53e+21 FLOP (Mid-era model: 7B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.905078,
gemma_3_4b,Google,,4000000000,1.92e+21,medium,scaling_laws,Benchmark Based: 3.74e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 4,000,000,000 params × 80,000,000,000 tokens = 1.92e+21 FLOP (Modern model: 4B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.888808,
gemma_3n_e4b,Google,,4000000000,1.92e+21,medium,scaling_laws,Benchmark Based: 3.84e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 4,000,000,000 params × 80,000,000,000 tokens = 1.92e+21 FLOP (Modern model: 4B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.887342,
qwen1.5_4b,Alibaba,,4000000000,1.54e+21,medium,scaling_laws,Benchmark Based: 9.76e+24 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 4,000,000,000 params × 64,000,000,000 tokens = 1.54e+21 FLOP (Chinese model: 4B params * 16 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.897786,
llama_3.2_3b,Meta,,3000000000,1.08e+21,medium,scaling_laws,Benchmark Based: 1.05e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 3,000,000,000 params × 60,000,000,000 tokens = 1.08e+21 FLOP (Modern model: 3B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.895805,
fastchat_t5_3b,LMSYS,,3000000000,9.72e+20,medium,scaling_laws,Benchmark Based: 9.85e+23 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 3,000,000,000 params × 54,000,000,000 tokens = 9.72e+20 FLOP (Specialized model: 3B params * 18 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.898385,
gemma_1.1_2b,Google,,2000000000,3.60e+20,low,scaling_laws,Benchmark Based: 1.03e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 2,000,000,000 params × 30,000,000,000 tokens = 3.60e+20 FLOP (Generic estimate: 2B params * 15 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.897676,
granite_3.0_2b,IBM,,2000000000,3.60e+20,low,scaling_laws,Benchmark Based: 9.78e+24 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 2,000,000,000 params × 30,000,000,000 tokens = 3.60e+20 FLOP (Generic estimate: 2B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.896086,
granite_3.1_2b,IBM,,2000000000,3.60e+20,low,scaling_laws,Benchmark Based: 1.64e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 2,000,000,000 params × 30,000,000,000 tokens = 3.60e+20 FLOP (Generic estimate: 2B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.894964,
gemma_2_2b,Google,,2000000000,2.88e+20,medium,scaling_laws,Benchmark Based: 1.77e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 2,000,000,000 params × 24,000,000,000 tokens = 2.88e+20 FLOP (Mid-era model: 2B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.894105,
gemma_2b,Google,,2000000000,2.88e+20,medium,scaling_laws,Benchmark Based: 9.78e+24 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 2,000,000,000 params × 24,000,000,000 tokens = 2.88e+20 FLOP (Mid-era model: 2B params * 12 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.897734,
smollm2_1.7b,HuggingFace,,1700000000,2.60e+20,low,scaling_laws,Benchmark Based: 1.62e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 1,700,000,000 params × 25,500,000,000 tokens = 2.60e+20 FLOP (Generic estimate: 2B params * 15 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-07-31T19:41:33.897076,
llama_3.2_1b,Meta,,1000000000,1.20e+20,medium,scaling_laws,Benchmark Based: 5.25e+24 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 1,000,000,000 params × 20,000,000,000 tokens = 1.20e+20 FLOP (Modern model: 1B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-07-31T19:41:33.897521,
