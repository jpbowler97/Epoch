model,developer,release_date,parameters,training_flop,confidence,estimation_method,alternative_methods,threshold_classification,status,reasoning,sources,verified,last_updated,notes,parameter_source,confidence_explanation,blacklist_status,original_estimate
grok_3_mini,xAI,,,4.379999999999999e+25,medium,benchmark_based,,high_confidence_below_1e25,confirmed_below_1e25,"Benchmark-based (openlm_arena_elo): Benchmark-based estimation: ELO 1363.0 vs reference llama_405b (ELO 1300, 3.80e+25 FLOP) with power law scaling α=3.0 = 4.38e+25 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),y,2025-08-01T15:52:46.887087,Moved from above_1e25_flop.csv by manual review. Reason: This is a mini model so likely smaller than 1e25,,,,
sora,OpenAI,,,1.00e+25,medium,benchmark_based,,high_confidence_below_1e25,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: video_arena_elo: 1.00e+25 (Medium); video_quality: 1.00e+25 (Medium) → weighted average: 1.00e+25 FLOP,https://artificialanalysis.ai/text-to-video/arena (Artificial Analysis Video Arena - Text-to-video model rankings),,2025-08-04T19:46:43.992726,,,Good benchmark match with multiple agreeing sources,allowed,
athene,NexusFlow,,,9.90e+24,low,benchmark_based,Benchmark Based: 3.63e+25 (Medium),high_confidence_below_1e25,uncertain,"FLOP estimate capped at 9.9e+24 due to developer blacklist policy: AI company with focus on open models and reasonable disclosure practices. Original estimate: 3.63e+25 FLOP (Benchmark-based (lmarena_score): 1315.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 3.63e+25 FLOP)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.966516,,,Distant benchmark interpolation or single source,capped,3.63e+25
baichuan_4,Unknown,,,9.90e+24,speculative,benchmark_based,Benchmark Based: 3.25e+25 (Low),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Models with unidentified developers cannot be properly evaluated - Cannot verify training methodology or model provenance. Original estimate: 3.25e+25 FLOP (Multi-benchmark estimation from 5 benchmarks: superclue_overall: 3.30e+25 (Medium); superclue_math: 2.91e+25 (Medium); superclue_reasoning: 1.06e+25 (Low); superclue_code: 3.67e+25 (Medium); superclue_agents: 4.58e+25 (Medium) → weighted average: 3.25e+25 FLOP),https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-04T19:46:43.995272,,,Very distant benchmark extrapolation,capped,3.25e+25
command_a,Cohere,,,9.90e+24,low,benchmark_based,Benchmark Based: 3.88e+25 (Medium),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Canadian AI company with reasonable disclosure standards and research focus. Original estimate: 3.88e+25 FLOP (Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 4.17e+25 (Medium); coding_score: 4.12e+25 (Medium); aai_score: 3.71e+25 (Medium); mmlu_pro_score: 3.55e+25 (Medium) → weighted average: 3.88e+25 FLOP),https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.988394,,,Distant benchmark interpolation or single source,capped,3.88e+25
command_a_03,Cohere,,,9.90e+24,low,benchmark_based,Benchmark Based: 3.90e+25 (Medium),high_confidence_below_1e25,uncertain,"FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Canadian AI company with reasonable disclosure standards and research focus. Original estimate: 3.90e+25 FLOP (Benchmark-based (lmarena_score): 1347.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 3.90e+25 FLOP)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.961437,,,Distant benchmark interpolation or single source,capped,3.90e+25
command_r,Cohere,,,9.90e+24,speculative,benchmark_based,Benchmark Based: 1.62e+25 (Low),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Canadian AI company with reasonable disclosure standards and research focus. Original estimate: 1.62e+25 FLOP (Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 2.85e+25 (Low); coding_score: 2.58e+25 (Low); aai_score: 5.01e+24 (Low); mmlu_pro_score: 5.46e+24 (Low) → weighted average: 1.62e+25 FLOP),https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.975395,,,Very distant benchmark extrapolation,capped,1.62e+25
command_r_08,Cohere,,,9.90e+24,low,benchmark_based,Benchmark Based: 3.14e+25 (Medium),high_confidence_below_1e25,uncertain,"FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Canadian AI company with reasonable disclosure standards and research focus. Original estimate: 3.14e+25 FLOP (Benchmark-based (lmarena_score): 1253.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 3.14e+25 FLOP)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.971879,,,Distant benchmark interpolation or single source,capped,3.14e+25
command_r_plus,Cohere,,,9.90e+24,low,benchmark_based,Benchmark Based: 3.24e+25 (Medium),high_confidence_below_1e25,uncertain,"FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Canadian AI company with reasonable disclosure standards and research focus. Original estimate: 3.24e+25 FLOP (Benchmark-based (lmarena_score): 1266.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 3.24e+25 FLOP)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.970930,,,Distant benchmark interpolation or single source,capped,3.24e+25
command_r_plus_08,Cohere,,,9.90e+24,low,benchmark_based,Benchmark Based: 3.36e+25 (Medium),high_confidence_below_1e25,uncertain,"FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Canadian AI company with reasonable disclosure standards and research focus. Original estimate: 3.36e+25 FLOP (Benchmark-based (lmarena_score): 1281.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 3.36e+25 FLOP)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.969736,,,Distant benchmark interpolation or single source,capped,3.36e+25
dbrx_instruct_preview,Databricks,,,9.90e+24,low,benchmark_based,Benchmark Based: 2.56e+25 (Medium),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Open source focused company with transparent model development practices. Original estimate: 2.56e+25 FLOP (Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 2.55e+25 (Low); coding_score: 2.58e+25 (Low) → weighted average: 2.56e+25 FLOP),https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.977703,,,Distant benchmark interpolation or single source,capped,2.56e+25
doubao_pro,ByteDance,,,9.90e+24,speculative,benchmark_based,Benchmark Based: 3.63e+25 (Low),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Chinese tech company with limited transparency on AI model training specifics - Limited disclosure on training methodology and data sources for frontier models. Original estimate: 3.63e+25 FLOP (Multi-benchmark estimation from 5 benchmarks: superclue_overall: 3.73e+25 (Medium); superclue_math: 3.13e+25 (Medium); superclue_reasoning: 1.55e+25 (Low); superclue_code: 3.89e+25 (Medium); superclue_agents: 5.15e+25 (Medium) → weighted average: 3.63e+25 FLOP),https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-04T19:46:43.993579,,,Very distant benchmark extrapolation,capped,3.63e+25
doubao_seed_1.6,ByteDance,,,9.90e+24,speculative,benchmark_based,Benchmark Based: 5.15e+25 (Low),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Chinese tech company with limited transparency on AI model training specifics - Limited disclosure on training methodology and data sources for frontier models. Original estimate: 5.15e+25 FLOP (Multi-benchmark estimation from 5 benchmarks: superclue_overall: 4.60e+25 (Medium); superclue_math: 4.64e+25 (Medium); superclue_reasoning: 1.33e+25 (Low); superclue_code: 5.63e+25 (Medium); superclue_agents: 8.29e+25 (Medium) → weighted average: 5.15e+25 FLOP),https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-04T19:46:43.993021,,,Very distant benchmark extrapolation,capped,5.15e+25
glm,Zhipu AI,,,9.90e+24,low,benchmark_based,Benchmark Based: 6.32e+25 (Medium),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Chinese AI company (same as Zhipu) with limited transparency on model training details - Insufficient disclosure on training compute and methodology. Original estimate: 6.32e+25 FLOP (Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 5.28e+25 (Low); coding_score: 5.24e+25 (Low); aai_score: 1.00e+26 (Low); mmlu_pro_score: 5.28e+25 (Medium) → weighted average: 6.32e+25 FLOP),https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.987257,,,Distant benchmark interpolation or single source,capped,6.32e+25
glm_4,Zhipu AI,,,9.90e+24,low,benchmark_based,Benchmark Based: 3.07e+25 (Medium),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Chinese AI company (same as Zhipu) with limited transparency on model training details - Insufficient disclosure on training compute and methodology. Original estimate: 3.07e+25 FLOP (Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.07e+25 (Medium); coding_score: 3.06e+25 (Medium) → weighted average: 3.07e+25 FLOP),https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.970143,,,Distant benchmark interpolation or single source,capped,3.07e+25
glm_4.5_air,Zhipu AI,,,9.90e+24,low,benchmark_based,Benchmark Based: 5.94e+25 (Medium),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Chinese AI company (same as Zhipu) with limited transparency on model training details - Insufficient disclosure on training compute and methodology. Original estimate: 5.94e+25 FLOP (Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 4.84e+25 (Low); coding_score: 4.97e+25 (Low); aai_score: 8.28e+25 (Medium); mmlu_pro_score: 4.97e+25 (Medium) → weighted average: 5.94e+25 FLOP),https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.987861,,,Distant benchmark interpolation or single source,capped,5.94e+25
glm_4_flash,Zhipu AI,,,9.90e+24,speculative,benchmark_based,Benchmark Based: 2.80e+25 (Low),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Chinese AI company (same as Zhipu) with limited transparency on model training details - Insufficient disclosure on training compute and methodology. Original estimate: 2.80e+25 FLOP (Multi-benchmark estimation from 5 benchmarks: superclue_overall: 2.70e+25 (Low); superclue_math: 1.93e+25 (Low); superclue_reasoning: 7.05e+24 (Low); superclue_code: 3.67e+25 (Medium); superclue_agents: 3.98e+25 (Medium) → weighted average: 2.80e+25 FLOP),https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-04T19:46:43.996042,,,Very distant benchmark extrapolation,capped,2.80e+25
glm_4_plus,Zhipu AI,,,9.90e+24,speculative,benchmark_based,Benchmark Based: 3.88e+25 (Low),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Chinese AI company (same as Zhipu) with limited transparency on model training details - Insufficient disclosure on training compute and methodology. Original estimate: 3.88e+25 FLOP (Multi-benchmark estimation from 5 benchmarks: superclue_overall: 3.90e+25 (Medium); superclue_math: 3.48e+25 (Medium); superclue_reasoning: 1.07e+25 (Low); superclue_code: 5.27e+25 (Medium); superclue_agents: 4.73e+25 (Medium) → weighted average: 3.88e+25 FLOP),https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-04T19:46:43.961901,,,Very distant benchmark extrapolation,capped,3.88e+25
hunyuan_large,Tencent,,,9.90e+24,low,benchmark_based,Benchmark Based: 3.88e+25 (Medium),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Major Chinese tech company but with limited transparency on AI model training specifics - Limited disclosure on training methodology and compute for frontier AI models. Original estimate: 3.88e+25 FLOP (Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.84e+25 (Medium); coding_score: 3.91e+25 (Medium) → weighted average: 3.88e+25 FLOP),https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.964556,,,Distant benchmark interpolation or single source,capped,3.88e+25
hunyuan_large_vision,Tencent,,,9.90e+24,low,benchmark_based,Benchmark Based: 3.73e+25 (Medium),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Major Chinese tech company but with limited transparency on AI model training specifics - Limited disclosure on training methodology and compute for frontier AI models. Original estimate: 3.73e+25 FLOP (Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.66e+25 (Medium); coding_score: 3.79e+25 (Medium) → weighted average: 3.73e+25 FLOP),https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.968056,,,Distant benchmark interpolation or single source,capped,3.73e+25
hunyuan_pro,Tencent,,,9.90e+24,speculative,benchmark_based,Benchmark Based: 3.78e+25 (Low),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Major Chinese tech company but with limited transparency on AI model training specifics - Limited disclosure on training methodology and compute for frontier AI models. Original estimate: 3.78e+25 FLOP (Multi-benchmark estimation from 5 benchmarks: superclue_overall: 3.78e+25 (Medium); superclue_math: 2.88e+25 (Medium); superclue_reasoning: 1.06e+25 (Low); superclue_code: 5.24e+25 (Medium); superclue_agents: 5.03e+25 (Medium) → weighted average: 3.78e+25 FLOP),https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-04T19:46:43.993403,,,Very distant benchmark extrapolation,capped,3.78e+25
hunyuan_standard,Tencent,,,9.90e+24,low,benchmark_based,Benchmark Based: 3.71e+25 (Medium),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Major Chinese tech company but with limited transparency on AI model training specifics - Limited disclosure on training methodology and compute for frontier AI models. Original estimate: 3.71e+25 FLOP (Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.71e+25 (Medium); coding_score: 3.71e+25 (Medium) → weighted average: 3.71e+25 FLOP),https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.966637,,,Distant benchmark interpolation or single source,capped,3.71e+25
hunyuan_standard_256k,Tencent,,,9.90e+24,low,benchmark_based,Benchmark Based: 3.25e+25 (Medium),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Major Chinese tech company but with limited transparency on AI model training specifics - Limited disclosure on training methodology and compute for frontier AI models. Original estimate: 3.25e+25 FLOP (Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.16e+25 (Medium); coding_score: 3.34e+25 (Medium) → weighted average: 3.25e+25 FLOP),https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.974150,,,Distant benchmark interpolation or single source,capped,3.25e+25
hunyuan_turbo,Tencent,,,9.90e+24,low,benchmark_based,Benchmark Based: 4.09e+25 (Medium),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Major Chinese tech company but with limited transparency on AI model training specifics - Limited disclosure on training methodology and compute for frontier AI models. Original estimate: 4.09e+25 FLOP (Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 4.05e+25 (Medium); coding_score: 4.12e+25 (Medium) → weighted average: 4.09e+25 FLOP),https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.962057,,,Distant benchmark interpolation or single source,capped,4.09e+25
hunyuan_turbos,Tencent,,,9.90e+24,low,benchmark_based,Benchmark Based: 4.58e+25 (Medium),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Major Chinese tech company but with limited transparency on AI model training specifics - Limited disclosure on training methodology and compute for frontier AI models. Original estimate: 4.58e+25 FLOP (Multi-benchmark estimation from 3 benchmarks: openlm_arena_elo: 4.67e+25 (Medium); coding_score: 4.64e+25 (Medium); mmlu_pro_score: 4.45e+25 (Medium) → weighted average: 4.58e+25 FLOP),https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.949416,,,Distant benchmark interpolation or single source,capped,4.58e+25
internlm_3,Unknown,,,9.90e+24,speculative,benchmark_based,Benchmark Based: 2.80e+25 (Low),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Models with unidentified developers cannot be properly evaluated - Cannot verify training methodology or model provenance. Original estimate: 2.80e+25 FLOP (Multi-benchmark estimation from 5 benchmarks: superclue_overall: 2.82e+25 (Medium); superclue_math: 3.10e+25 (Medium); superclue_reasoning: 1.18e+25 (Low); superclue_code: 2.11e+25 (Low); superclue_agents: 4.04e+25 (Medium) → weighted average: 2.80e+25 FLOP),https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-04T19:46:43.995750,,,Very distant benchmark extrapolation,capped,2.80e+25
jamba_1.5_large,AI21 Labs,,,9.90e+24,low,benchmark_based,Benchmark Based: 2.70e+25 (Medium),high_confidence_below_1e25,uncertain,"FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Israeli AI company with reasonable disclosure standards, academic backing. Original estimate: 2.70e+25 FLOP (Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 3.42e+25 (Medium); coding_score: 3.34e+25 (Medium); aai_score: 1.99e+25 (Medium); mmlu_pro_score: 2.05e+25 (Medium) → weighted average: 2.70e+25 FLOP)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.968843,,,Distant benchmark interpolation or single source,capped,2.70e+25
jamba_1.5_mini,AI21 Labs,,,9.90e+24,low,benchmark_based,Benchmark Based: 3.01e+25 (Medium),high_confidence_below_1e25,uncertain,"FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Israeli AI company with reasonable disclosure standards, academic backing. Original estimate: 3.01e+25 FLOP (Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.03e+25 (Medium); coding_score: 2.97e+25 (Low) → weighted average: 3.01e+25 FLOP)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.973957,,,Distant benchmark interpolation or single source,capped,3.01e+25
lumiere,Unknown,,,9.90e+24,low,benchmark_based,Benchmark Based: 1.10e+25 (Medium),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Models with unidentified developers cannot be properly evaluated - Cannot verify training methodology or model provenance. Original estimate: 1.10e+25 FLOP (Threshold-based (physics_iq_score): 19.0 > sora (10.0) → assumed >1e25 FLOP (reference model assumed frontier-level)),https://physics-iq.github.io/ (Physics-IQ - Benchmark for physical understanding in video generation models),,2025-08-04T19:46:43.992292,,,Distant benchmark interpolation or single source,capped,1.10e+25
minimax_01,MiniMax,,,9.90e+24,speculative,benchmark_based,Benchmark Based: 3.60e+25 (Low),high_confidence_below_1e25,uncertain,"FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Chinese AI company with very limited transparency on model specifications - Insufficient disclosure on training methodology, data sources, and model architecture. Original estimate: 3.60e+25 FLOP (Multi-benchmark estimation from 5 benchmarks: superclue_overall: 3.55e+25 (Medium); superclue_math: 2.48e+25 (Low); superclue_reasoning: 1.18e+25 (Low); superclue_code: 4.23e+25 (Medium); superclue_agents: 5.39e+25 (Medium) → weighted average: 3.60e+25 FLOP)",https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-04T19:46:43.994848,,,Very distant benchmark extrapolation,capped,3.60e+25
minimax_m1,MiniMax,,,9.90e+24,speculative,benchmark_based,Benchmark Based: 5.45e+25 (Low),high_confidence_below_1e25,uncertain,"FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Chinese AI company with very limited transparency on model specifications - Insufficient disclosure on training methodology, data sources, and model architecture. Original estimate: 5.45e+25 FLOP (Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 4.44e+25 (Medium); coding_score: 4.45e+25 (Medium); aai_score: 9.20e+25 (Low); mmlu_pro_score: 4.99e+25 (Medium) → weighted average: 5.45e+25 FLOP)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.949609,,,Very distant benchmark extrapolation,capped,5.45e+25
moonshot,Unknown,,,9.90e+24,speculative,benchmark_based,Benchmark Based: 3.44e+25 (Low),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Models with unidentified developers cannot be properly evaluated - Cannot verify training methodology or model provenance. Original estimate: 3.44e+25 FLOP (Multi-benchmark estimation from 5 benchmarks: superclue_overall: 3.49e+25 (Medium); superclue_math: 2.90e+25 (Medium); superclue_reasoning: 1.24e+25 (Low); superclue_code: 3.42e+25 (Medium); superclue_agents: 5.44e+25 (Medium) → weighted average: 3.44e+25 FLOP),https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-04T19:46:43.995054,,,Very distant benchmark extrapolation,capped,3.44e+25
o4_mini,Unknown,,,9.90e+24,low,benchmark_based,Benchmark Based: 5.47e+25 (Medium),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Models with unidentified developers cannot be properly evaluated - Cannot verify training methodology or model provenance. Original estimate: 5.47e+25 FLOP (Multi-benchmark estimation from 5 benchmarks: superclue_overall: 5.55e+25 (Medium); superclue_math: 5.61e+25 (Medium); superclue_reasoning: 2.94e+25 (Medium); superclue_code: 5.93e+25 (Medium); superclue_agents: 7.34e+25 (Medium) → weighted average: 5.47e+25 FLOP),https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-04T19:46:43.947084,,,Distant benchmark interpolation or single source,capped,5.47e+25
openchat,OpenChat,,,9.90e+24,low,benchmark_based,Benchmark Based: 2.28e+25 (Medium),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Open source project with transparent development practices. Original estimate: 2.28e+25 FLOP (Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 2.40e+25 (Low); coding_score: 2.17e+25 (Low) → weighted average: 2.28e+25 FLOP),https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.978300,,,Distant benchmark interpolation or single source,capped,2.28e+25
phi_3_medium_4k,Microsoft,,,9.90e+24,low,benchmark_based,Benchmark Based: 2.01e+25 (Medium),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: So far they are not generating large proprietary models. Original estimate: 2.01e+25 FLOP (Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 2.68e+25 (Low); coding_score: 2.61e+25 (Low); aai_score: 1.39e+25 (Medium); mmlu_pro_score: 1.80e+25 (Medium) → weighted average: 2.01e+25 FLOP),https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.976763,,,Distant benchmark interpolation or single source,capped,2.01e+25
phi_3_mini_128k,Microsoft,,,9.90e+24,speculative,benchmark_based,Benchmark Based: 2.35e+25 (Low),high_confidence_below_1e25,uncertain,"FLOP estimate capped at 9.9e+24 due to developer blacklist policy: So far they are not generating large proprietary models. Original estimate: 2.35e+25 FLOP (Benchmark-based (lmarena_score): 1138.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 2.35e+25 FLOP)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.984108,,,Very distant benchmark extrapolation,capped,2.35e+25
phi_3_mini_4k,Microsoft,,,9.90e+24,low,benchmark_based,Benchmark Based: 2.29e+25 (Medium),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: So far they are not generating large proprietary models. Original estimate: 2.29e+25 FLOP (Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 2.26e+25 (Low); coding_score: 2.32e+25 (Low) → weighted average: 2.29e+25 FLOP),https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.984533,,,Distant benchmark interpolation or single source,capped,2.29e+25
phi_3_mini_4k_instruct_june,Microsoft,,,9.90e+24,speculative,benchmark_based,Benchmark Based: 2.42e+25 (Low),high_confidence_below_1e25,uncertain,"FLOP estimate capped at 9.9e+24 due to developer blacklist policy: So far they are not generating large proprietary models. Original estimate: 2.42e+25 FLOP (Benchmark-based (lmarena_score): 1149.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 2.42e+25 FLOP)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.982889,,,Very distant benchmark extrapolation,capped,2.42e+25
phi_3_mini_4k_instruct_june_24,Microsoft,,,9.90e+24,low,benchmark_based,Benchmark Based: 2.30e+25 (Medium),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: So far they are not generating large proprietary models. Original estimate: 2.30e+25 FLOP (Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 2.30e+25 (Low); coding_score: 2.29e+25 (Low) → weighted average: 2.30e+25 FLOP),https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.990990,,,Distant benchmark interpolation or single source,capped,2.30e+25
phi_3_small_8k,Microsoft,,,9.90e+24,low,benchmark_based,Benchmark Based: 2.47e+25 (Medium),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: So far they are not generating large proprietary models. Original estimate: 2.47e+25 FLOP (Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 2.49e+25 (Low); coding_score: 2.46e+25 (Low) → weighted average: 2.47e+25 FLOP),https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.979358,,,Distant benchmark interpolation or single source,capped,2.47e+25
phi_4,Microsoft,,,9.90e+24,low,benchmark_based,Benchmark Based: 3.47e+25 (Medium),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: So far they are not generating large proprietary models. Original estimate: 3.47e+25 FLOP (Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 3.26e+25 (Medium); coding_score: 3.32e+25 (Medium); aai_score: 3.74e+25 (Medium); mmlu_pro_score: 3.57e+25 (Medium) → weighted average: 3.47e+25 FLOP),https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.971768,,,Distant benchmark interpolation or single source,capped,3.47e+25
pika,Unknown,,,9.9e+24,low,benchmark_based,Benchmark Based: 1.10e+25 (Medium),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Cannot verify training methodology or model provenance. Original estimate: 1.10e+25 FLOP (Threshold-based (physics_iq_score): 13.0 > sora (10.0) → assumed >1e25 FLOP (reference model assumed frontier-level)),https://physics-iq.github.io/ (Physics-IQ - Benchmark for physical understanding in video generation models),,2025-08-04T19:29:36.670402,,,Distant benchmark interpolation or single source,capped,1.0999999999999998e+25
reka_core,Reka AI,,,9.90e+24,low,benchmark_based,Benchmark Based: 3.34e+25 (Medium),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: AI company with research focus and reasonable disclosure practices. Original estimate: 3.34e+25 FLOP (Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.49e+25 (Medium); coding_score: 3.19e+25 (Medium) → weighted average: 3.34e+25 FLOP),https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.968988,,,Distant benchmark interpolation or single source,capped,3.34e+25
reka_flash,Reka AI,,,9.90e+24,low,benchmark_based,Benchmark Based: 3.12e+25 (Medium),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: AI company with research focus and reasonable disclosure practices. Original estimate: 3.12e+25 FLOP (Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.23e+25 (Medium); coding_score: 3.00e+25 (Medium) → weighted average: 3.12e+25 FLOP),https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.970015,,,Distant benchmark interpolation or single source,capped,3.12e+25
snowflake_arctic,Snowflake,,,9.90e+24,low,benchmark_based,Benchmark Based: 2.38e+25 (Medium),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Data platform company with transparent model development practices. Original estimate: 2.38e+25 FLOP (Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 2.44e+25 (Low); coding_score: 2.31e+25 (Low) → weighted average: 2.38e+25 FLOP),https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.978899,,,Distant benchmark interpolation or single source,capped,2.38e+25
step_2,StepFun,,,9.90e+24,low,benchmark_based,Benchmark Based: 4.02e+25 (Medium),high_confidence_below_1e25,uncertain,"FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Chinese AI company with very limited public information on model training - Extremely limited disclosure on training compute, methodology, and specifications. Original estimate: 4.02e+25 FLOP (Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 4.12e+25 (Medium); coding_score: 3.92e+25 (Medium) → weighted average: 4.02e+25 FLOP)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.962775,,,Distant benchmark interpolation or single source,capped,4.02e+25
step_2_16k,StepFun,,,9.90e+24,speculative,benchmark_based,Benchmark Based: 3.57e+25 (Low),high_confidence_below_1e25,uncertain,"FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Chinese AI company with very limited public information on model training - Extremely limited disclosure on training compute, methodology, and specifications. Original estimate: 3.57e+25 FLOP (Multi-benchmark estimation from 5 benchmarks: superclue_overall: 3.61e+25 (Medium); superclue_math: 3.99e+25 (Medium); superclue_reasoning: 1.10e+25 (Low); superclue_code: 3.52e+25 (Medium); superclue_agents: 4.83e+25 (Medium) → weighted average: 3.57e+25 FLOP)",https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-04T19:46:43.994363,,,Very distant benchmark extrapolation,capped,3.57e+25
videopoet,Unknown,,,9.90e+24,low,benchmark_based,Benchmark Based: 1.10e+25 (Medium),high_confidence_below_1e25,uncertain,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Models with unidentified developers cannot be properly evaluated - Cannot verify training methodology or model provenance. Original estimate: 1.10e+25 FLOP (Threshold-based (physics_iq_score): 20.3 > sora (10.0) → assumed >1e25 FLOP (reference model assumed frontier-level)),https://physics-iq.github.io/ (Physics-IQ - Benchmark for physical understanding in video generation models),,2025-08-04T19:46:43.992161,,,Distant benchmark interpolation or single source,capped,1.10e+25
yi_large,01 AI,,,9.90e+24,low,benchmark_based,Benchmark Based: 2.60e+25 (Medium),high_confidence_below_1e25,uncertain,"FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Chinese AI company founded by Kai-Fu Lee, relatively new but has some disclosure. Original estimate: 2.60e+25 FLOP (Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 3.37e+25 (Low); coding_score: 3.29e+25 (Medium); aai_score: 1.80e+25 (Medium); mmlu_pro_score: 2.18e+25 (Medium) → weighted average: 2.60e+25 FLOP)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.989798,,,Distant benchmark interpolation or single source,capped,2.60e+25
yi_lightning,01 AI,,,9.90e+24,speculative,benchmark_based,Benchmark Based: 3.84e+25 (Low),high_confidence_below_1e25,uncertain,"FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Chinese AI company founded by Kai-Fu Lee, relatively new but has some disclosure. Original estimate: 3.84e+25 FLOP (Multi-benchmark estimation from 5 benchmarks: superclue_overall: 3.93e+25 (Medium); superclue_math: 3.65e+25 (Medium); superclue_reasoning: 1.32e+25 (Low); superclue_code: 4.51e+25 (Medium); superclue_agents: 4.93e+25 (Medium) → weighted average: 3.84e+25 FLOP)",https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-04T19:46:43.964377,,,Very distant benchmark extrapolation,capped,3.84e+25
yi_lightning_lite,01 AI,,,9.90e+24,low,benchmark_based,Benchmark Based: 3.73e+25 (Medium),high_confidence_below_1e25,uncertain,"FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Chinese AI company founded by Kai-Fu Lee, relatively new but has some disclosure. Original estimate: 3.73e+25 FLOP (Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.78e+25 (Medium); coding_score: 3.69e+25 (Medium) → weighted average: 3.73e+25 FLOP)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.989208,,,Distant benchmark interpolation or single source,capped,3.73e+25
seedance,Unknown,,,9.25e+24,medium,benchmark_based,,high_confidence_below_1e25,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: video_arena_elo: 9.31e+24 (Low); video_quality: 9.19e+24 (Low) → weighted average: 9.25e+24 FLOP,https://artificialanalysis.ai/text-to-video/arena (Artificial Analysis Video Arena - Text-to-video model rankings),,2025-08-04T19:46:43.996938,,,Good benchmark match with multiple agreeing sources,allowed,
waver,Unknown,,,8.81e+24,medium,benchmark_based,,high_confidence_below_1e25,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: video_arena_elo: 8.90e+24 (Low); video_quality: 8.72e+24 (Low) → weighted average: 8.81e+24 FLOP,https://artificialanalysis.ai/text-to-video/arena (Artificial Analysis Video Arena - Text-to-video model rankings),,2025-08-04T19:46:43.997002,,,Good benchmark match with multiple agreeing sources,allowed,
deepseek_coder_v2,DeepSeek,,236000000000.0,8.50e+24,medium,scaling_laws,Benchmark Based: 3.26e+25 (Medium),high_confidence_below_1e25,likely_above_1e25,"Known model specification 'deepseek_coder_v2': Chinchilla scaling law: 6 × 236,000,000,000 params × 6,000,000,000,000 tokens = 8.50e+24 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.971163,,known_specification:deepseek_coder_v2,Known parameters with estimated training tokens,allowed,
runway_gen3,Unknown,,,7.87e+24,medium,benchmark_based,,high_confidence_below_1e25,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: video_arena_elo: 8.22e+24 (Low); video_quality: 7.52e+24 (Low) → weighted average: 7.87e+24 FLOP,https://artificialanalysis.ai/text-to-video/arena (Artificial Analysis Video Arena - Text-to-video model rankings),,2025-08-04T18:55:00.258921,,,Good benchmark match with multiple agreeing sources,allowed,
kling,Unknown,,,7.35e+24,medium,benchmark_based,,high_confidence_below_1e25,likely_above_1e25,Multi-benchmark estimation from 2 benchmarks: video_arena_elo: 7.76e+24 (Low); video_quality: 6.93e+24 (Low) → weighted average: 7.35e+24 FLOP,https://artificialanalysis.ai/text-to-video/arena (Artificial Analysis Video Arena - Text-to-video model rankings),,2025-08-04T19:46:43.997238,,,Good benchmark match with multiple agreeing sources,allowed,
llama_3.1_70b,Meta,,70000000000.0,6.30e+24,high,scaling_laws,Benchmark Based: 2.23e+25 (Low),high_confidence_below_1e25,confirmed_below_1e25,"Known model specification 'llama_3.1_70b': Chinchilla scaling law: 6 × 70,000,000,000 params × 15,000,000,000,000 tokens = 6.30e+24 FLOP",https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-04T19:46:43.968425,,known_specification:llama_3.1_70b,Known parameters with documented training tokens,allowed,
llama_3_70b,Meta,,70000000000.0,6.30e+24,high,scaling_laws,Benchmark Based: 2.55e+25 (Medium),high_confidence_below_1e25,confirmed_below_1e25,"Known model specification 'llama_3_70b': Chinchilla scaling law: 6 × 70,000,000,000 params × 15,000,000,000,000 tokens = 6.30e+24 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.970271,,known_specification:llama_3_70b,Known parameters with documented training tokens,allowed,
llama_3.1_nemotron_ultra_253b,Nvidia,,253000000000.0,5.76e+24,medium,scaling_laws,Benchmark Based: 4.17e+25 (Medium),high_confidence_below_1e25,likely_above_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 253,000,000,000 params × 3,795,000,000,000 tokens = 5.76e+24 FLOP (Modern large model: 253B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.787773,,extracted_from_name,Known parameters with estimated training tokens,,
llama_3.1_nemotron_ultra_253b_v1,Meta,,253000000000.0,5.76e+24,medium,scaling_laws,Benchmark Based: 5.23e+25 (Low),high_confidence_below_1e25,likely_above_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 253,000,000,000 params × 3,795,000,000,000 tokens = 5.76e+24 FLOP (Modern large model: 253B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.960726,,extracted_from_name,Known parameters with estimated training tokens,allowed,
qwen3_235b_a22b,Alibaba,,235000000000.0,4.97e+24,medium,scaling_laws,Benchmark Based: 6.02e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 235,000,000,000 params × 3,525,000,000,000 tokens = 4.97e+24 FLOP (Modern large model: 235B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.946880,,extracted_from_name,Known parameters with estimated training tokens,allowed,
deepseek_r1,DeepSeek,,671000000000.0,3.00e+24,high,epoch_estimate,Scaling Laws: 6.04e+25 (Low); Benchmark Based: 5.76e+25 (Medium),high_confidence_below_1e25,confirmed_below_1e25,https://epoch.ai/gradient-updates/what-went-into-training-deepseek-r1,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.945414,,known_specification:deepseek_r1,Official disclosure or high-precision research estimate,allowed,
falcon_180b,TII,,180000000000.0,2.92e+24,low,scaling_laws,Benchmark Based: 2.40e+25 (Low),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 180,000,000,000 params × 2,700,000,000,000 tokens = 2.92e+24 FLOP (Generic estimate: 180B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.982490,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
zephyr_orpo_141b,HuggingFace,,141000000000.0,1.79e+24,low,scaling_laws,Benchmark Based: 2.66e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 141,000,000,000 params × 2,115,000,000,000 tokens = 1.79e+24 FLOP (Generic estimate: 141B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.809406,,extracted_from_name,Extracted parameters with uncertain training tokens,,
qwen1.5_110b,Alibaba,,110000000000.0,1.16e+24,medium,scaling_laws,Benchmark Based: 2.30e+25 (Low),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 110,000,000,000 params × 1,760,000,000,000 tokens = 1.16e+24 FLOP (Chinese model: 110B params * 16 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.974424,,extracted_from_name,Known parameters with estimated training tokens,allowed,
llama_3.2_90b_vision,Meta,,90000000000.0,9.72e+23,medium,scaling_laws,Benchmark Based: 2.82e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 90,000,000,000 params × 1,800,000,000,000 tokens = 9.72e+23 FLOP (Modern model: 90B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.991654,,extracted_from_name,Known parameters with estimated training tokens,allowed,
llama_2_70b,Meta,,70000000000.0,8.40e+23,high,scaling_laws,Benchmark Based: 1.66e+25 (Low),high_confidence_below_1e25,confirmed_below_1e25,"Known model specification 'llama_2_70b': Chinchilla scaling law: 6 × 70,000,000,000 params × 2,000,000,000,000 tokens = 8.40e+23 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.979638,,known_specification:llama_2_70b,Known parameters with documented training tokens,allowed,
llama_3.1_8b,Meta,,8000000000.0,7.20e+23,high,scaling_laws,Benchmark Based: 2.24e+25 (Low),high_confidence_below_1e25,confirmed_below_1e25,"Known model specification 'llama_3.1_8b': Chinchilla scaling law: 6 × 8,000,000,000 params × 15,000,000,000,000 tokens = 7.20e+23 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.976498,,known_specification:llama_3.1_8b,Known parameters with documented training tokens,allowed,
llama_3_8b,Meta,,8000000000.0,7.20e+23,high,scaling_laws,Benchmark Based: 1.79e+25 (Low),high_confidence_below_1e25,confirmed_below_1e25,"Known model specification 'llama_3_8b': Chinchilla scaling law: 6 × 8,000,000,000 params × 15,000,000,000,000 tokens = 7.20e+23 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.976041,,known_specification:llama_3_8b,Known parameters with documented training tokens,allowed,
llama_3.1_nemotron_70b,Nvidia,,70000000000.0,5.88e+23,medium,scaling_laws,Benchmark Based: 3.75e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,400,000,000,000 tokens = 5.88e+23 FLOP (Modern model: 70B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.801637,,extracted_from_name,Known parameters with estimated training tokens,,
llama_3.1_tulu_3_70b,Ai2,,70000000000.0,5.88e+23,medium,scaling_laws,Benchmark Based: 3.48e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,400,000,000,000 tokens = 5.88e+23 FLOP (Modern model: 70B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.802087,,extracted_from_name,Known parameters with estimated training tokens,,
llama_3.3_70b,Meta,,70000000000.0,5.88e+23,medium,scaling_laws,Benchmark Based: 2.78e+25 (Low),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,400,000,000,000 tokens = 5.88e+23 FLOP (Modern model: 70B params * 20 tokens/param)",https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-04T19:46:43.965979,,extracted_from_name,Known parameters with estimated training tokens,allowed,
athene_v2_chat_72b,NexusFlow,,72000000000.0,5.60e+23,medium,scaling_laws,Benchmark Based: 3.93e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 72,000,000,000 params × 1,296,000,000,000 tokens = 5.60e+23 FLOP (Specialized model: 72B params * 18 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.989068,,extracted_from_name,Known parameters with estimated training tokens,allowed,
codellama_70b,Meta,,70000000000.0,5.29e+23,medium,scaling_laws,Benchmark Based: 2.31e+25 (Low),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,260,000,000,000 tokens = 5.29e+23 FLOP (Specialized model: 70B params * 18 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.983768,,extracted_from_name,Known parameters with estimated training tokens,allowed,
qwen1.5_72b,Alibaba,,72000000000.0,4.98e+23,medium,scaling_laws,Benchmark Based: 2.84e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 72,000,000,000 params × 1,152,000,000,000 tokens = 4.98e+23 FLOP (Chinese model: 72B params * 16 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.974524,,extracted_from_name,Known parameters with estimated training tokens,allowed,
molmo_72b,Ai2,,72000000000.0,4.67e+23,low,scaling_laws,,high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 72,000,000,000 params × 1,080,000,000,000 tokens = 4.67e+23 FLOP (Generic estimate: 72B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.823172,,extracted_from_name,Extracted parameters with uncertain training tokens,,
athene_70b,NexusFlow,,70000000000.0,4.41e+23,low,scaling_laws,Benchmark Based: 3.61e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,050,000,000,000 tokens = 4.41e+23 FLOP (Generic estimate: 70B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.967612,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
llama2_70b_steerlm,Nvidia,,70000000000.0,4.41e+23,low,scaling_laws,Benchmark Based: 2.52e+25 (Low),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,050,000,000,000 tokens = 4.41e+23 FLOP (Generic estimate: 70B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.981701,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
nv_llama2_70b_steerlm,Nvidia,,70000000000.0,4.41e+23,low,scaling_laws,Benchmark Based: 2.20e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,050,000,000,000 tokens = 4.41e+23 FLOP (Generic estimate: 70B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.822656,,extracted_from_name,Extracted parameters with uncertain training tokens,,
pplx_70b_online,Perplexity AI,,70000000000.0,4.41e+23,low,scaling_laws,Benchmark Based: 2.20e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,050,000,000,000 tokens = 4.41e+23 FLOP (Generic estimate: 70B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.822751,,extracted_from_name,Extracted parameters with uncertain training tokens,,
tulu_2_dpo_70b,Ai2,,70000000000.0,4.41e+23,low,scaling_laws,Benchmark Based: 2.50e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,050,000,000,000 tokens = 4.41e+23 FLOP (Generic estimate: 70B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.812531,,extracted_from_name,Extracted parameters with uncertain training tokens,,
wizardlm_70b,Microsoft,,70000000000.0,4.41e+23,low,scaling_laws,Benchmark Based: 2.41e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 70,000,000,000 params × 1,050,000,000,000 tokens = 4.41e+23 FLOP (Generic estimate: 70B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.810522,,extracted_from_name,Extracted parameters with uncertain training tokens,,
deepseek_llm_67b,DeepSeek,,67000000000.0,4.04e+23,low,scaling_laws,Benchmark Based: 1.91e+25 (Low),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 67,000,000,000 params × 1,005,000,000,000 tokens = 4.04e+23 FLOP (Generic estimate: 67B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.978102,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
qwen2.5_72b,Alibaba,,72000000000.0,3.73e+23,medium,scaling_laws,Benchmark Based: 2.89e+25 (Low),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 72,000,000,000 params × 864,000,000,000 tokens = 3.73e+23 FLOP (Mid-era model: 72B params * 12 tokens/param)",https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-04T19:46:43.967754,,extracted_from_name,Known parameters with estimated training tokens,allowed,
qwen2.5_vl_72b,Alibaba,,72000000000.0,3.73e+23,medium,scaling_laws,,high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 72,000,000,000 params × 864,000,000,000 tokens = 3.73e+23 FLOP (Mid-era model: 72B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.991128,,extracted_from_name,Known parameters with estimated training tokens,allowed,
qwen2_72b,Alibaba,,72000000000.0,3.73e+23,medium,scaling_laws,Benchmark Based: 2.80e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 72,000,000,000 params × 864,000,000,000 tokens = 3.73e+23 FLOP (Mid-era model: 72B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.970795,,extracted_from_name,Known parameters with estimated training tokens,allowed,
qwen2_vl_72b,Alibaba,,72000000000.0,3.73e+23,medium,scaling_laws,,high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 72,000,000,000 params × 864,000,000,000 tokens = 3.73e+23 FLOP (Mid-era model: 72B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.991337,,extracted_from_name,Known parameters with estimated training tokens,allowed,
llama_3.1_nemotron_51b,Nvidia,,51000000000.0,3.12e+23,medium,scaling_laws,Benchmark Based: 3.27e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 51,000,000,000 params × 1,020,000,000,000 tokens = 3.12e+23 FLOP (Modern model: 51B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.802247,,extracted_from_name,Known parameters with estimated training tokens,,
llama_3.3_nemotron_49b_super,Nvidia,,49000000000.0,2.88e+23,medium,scaling_laws,Benchmark Based: 3.72e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 49,000,000,000 params × 980,000,000,000 tokens = 2.88e+23 FLOP (Modern model: 49B params * 20 tokens/param)",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),,2025-08-01T21:13:48.797907,,extracted_from_name,Known parameters with estimated training tokens,,
llama_3.3_nemotron_49b_super_v1,Nvidia,,49000000000.0,2.88e+23,medium,scaling_laws,Benchmark Based: 3.72e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 49,000,000,000 params × 980,000,000,000 tokens = 2.88e+23 FLOP (Modern model: 49B params * 20 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.964152,,extracted_from_name,Known parameters with estimated training tokens,allowed,
llama_3.3_nemotron_super_49b,Nvidia,,49000000000.0,2.88e+23,medium,scaling_laws,Benchmark Based: 4.00e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 49,000,000,000 params × 980,000,000,000 tokens = 2.88e+23 FLOP (Modern model: 49B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.820966,,extracted_from_name,Known parameters with estimated training tokens,,
llama_3.3_nemotron_super_49b_v1,Meta,,49000000000.0,2.88e+23,medium,scaling_laws,Benchmark Based: 4.65e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 49,000,000,000 params × 980,000,000,000 tokens = 2.88e+23 FLOP (Modern model: 49B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.988821,,extracted_from_name,Known parameters with estimated training tokens,allowed,
llama_3.3_nemotron_super_49b_v1.5,Meta,,49000000000.0,2.88e+23,medium,scaling_laws,Benchmark Based: 5.40e+25 (Low),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 49,000,000,000 params × 980,000,000,000 tokens = 2.88e+23 FLOP (Modern model: 49B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.988218,,extracted_from_name,Known parameters with estimated training tokens,allowed,
codellama_34b,Meta,,34000000000.0,1.39e+23,medium,scaling_laws,Benchmark Based: 2.15e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 34,000,000,000 params × 680,000,000,000 tokens = 1.39e+23 FLOP (Modern model: 34B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.983344,,extracted_from_name,Known parameters with estimated training tokens,allowed,
qwen3_32b,Alibaba,,32000000000.0,1.23e+23,medium,scaling_laws,Benchmark Based: 5.42e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 640,000,000,000 tokens = 1.23e+23 FLOP (Modern model: 32B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.961717,,extracted_from_name,Known parameters with estimated training tokens,allowed,
yi_1.5_34b,01 AI,,34000000000.0,1.11e+23,medium,scaling_laws,Benchmark Based: 2.33e+25 (Low),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 34,000,000,000 params × 544,000,000,000 tokens = 1.11e+23 FLOP (Chinese model: 34B params * 16 tokens/param)",https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-04T19:46:43.976277,,extracted_from_name,Known parameters with estimated training tokens,allowed,
yi_34b,01 AI,,34000000000.0,1.11e+23,medium,scaling_laws,Benchmark Based: 2.55e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 34,000,000,000 params × 544,000,000,000 tokens = 1.11e+23 FLOP (Chinese model: 34B params * 16 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.978172,,extracted_from_name,Known parameters with estimated training tokens,allowed,
qwen3_30b,Alibaba,,30000000000.0,1.08e+23,medium,scaling_laws,Benchmark Based: 4.98e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 30,000,000,000 params × 600,000,000,000 tokens = 1.08e+23 FLOP (Modern model: 30B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.963945,,extracted_from_name,Known parameters with estimated training tokens,allowed,
qwen1.5_32b,Alibaba,,32000000000.0,9.83e+22,medium,scaling_laws,Benchmark Based: 2.70e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 512,000,000,000 tokens = 9.83e+22 FLOP (Chinese model: 32B params * 16 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.976591,,extracted_from_name,Known parameters with estimated training tokens,allowed,
guanaco_33b,UW,,33000000000.0,9.80e+22,low,scaling_laws,Benchmark Based: 2.30e+25 (Low),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 33,000,000,000 params × 495,000,000,000 tokens = 9.80e+22 FLOP (Generic estimate: 33B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.984614,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
vicuna_33b,LMSYS,,33000000000.0,9.8e+22,low,scaling_laws,Benchmark Based: 2.36e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 33,000,000,000 params × 495,000,000,000 tokens = 9.80e+22 FLOP (Generic estimate: 33B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.813401,,extracted_from_name,Extracted parameters with uncertain training tokens,,
aya_expanse_32b,Cohere,,32000000000.0,9.22e+22,low,scaling_laws,Benchmark Based: 3.20e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 480,000,000,000 tokens = 9.22e+22 FLOP (Generic estimate: 32B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.822168,,extracted_from_name,Extracted parameters with uncertain training tokens,,
aya_vision_32b,Cohere,,32000000000.0,9.22e+22,low,scaling_laws,,high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 480,000,000,000 tokens = 9.22e+22 FLOP (Generic estimate: 32B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.823384,,extracted_from_name,Extracted parameters with uncertain training tokens,,
c4ai_aya_expanse_32b,Cohere,,32000000000.0,9.22e+22,low,scaling_laws,Benchmark Based: 3.26e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 480,000,000,000 tokens = 9.22e+22 FLOP (Generic estimate: 32B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.970586,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
olmo_2_32b,Ai2,,32000000000.0,9.22e+22,low,scaling_laws,Benchmark Based: 3.19e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 480,000,000,000 tokens = 9.22e+22 FLOP (Generic estimate: 32B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.806630,,extracted_from_name,Extracted parameters with uncertain training tokens,,
qwq_32b,Alibaba,,32000000000.0,9.22e+22,low,scaling_laws,Benchmark Based: 4.23e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 480,000,000,000 tokens = 9.22e+22 FLOP (Generic estimate: 32B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.794678,,extracted_from_name,Extracted parameters with uncertain training tokens,,
qwq_32b_preview,Alibaba,,32000000000.0,9.22e+22,low,scaling_laws,Benchmark Based: 2.58e+25 (Low),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 480,000,000,000 tokens = 9.22e+22 FLOP (Generic estimate: 32B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.981064,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
gemma_3_27b,Google,,27000000000.0,8.75e+22,medium,scaling_laws,Benchmark Based: 4.36e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 27,000,000,000 params × 540,000,000,000 tokens = 8.75e+22 FLOP (Modern model: 27B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.787558,,extracted_from_name,Known parameters with estimated training tokens,,
llama_2_7b,Meta,,7000000000.0,8.40e+22,high,scaling_laws,Benchmark Based: 2.20e+25 (Low),high_confidence_below_1e25,confirmed_below_1e25,"Known model specification 'llama_2_7b': Chinchilla scaling law: 6 × 7,000,000,000 params × 2,000,000,000,000 tokens = 8.40e+22 FLOP",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.985055,,known_specification:llama_2_7b,Known parameters with documented training tokens,allowed,
mpt_30b,MosaicML,,30000000000.0,8.1e+22,low,scaling_laws,Benchmark Based: 2.13e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 30,000,000,000 params × 450,000,000,000 tokens = 8.10e+22 FLOP (Generic estimate: 30B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.815135,,extracted_from_name,Extracted parameters with uncertain training tokens,,
qwen2.5_coder_32b,Alibaba,,32000000000.0,7.37e+22,medium,scaling_laws,Benchmark Based: 3.18e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 384,000,000,000 tokens = 7.37e+22 FLOP (Mid-era model: 32B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.970511,,extracted_from_name,Known parameters with estimated training tokens,allowed,
qwen2.5_vl_32b,Alibaba,,32000000000.0,7.37e+22,medium,scaling_laws,,high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 32,000,000,000 params × 384,000,000,000 tokens = 7.37e+22 FLOP (Mid-era model: 32B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.991059,,extracted_from_name,Known parameters with estimated training tokens,allowed,
internvl2_26b,OpenGVLab,,26000000000.0,6.08e+22,low,scaling_laws,,high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 26,000,000,000 params × 390,000,000,000 tokens = 6.08e+22 FLOP (Generic estimate: 26B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.823259,,extracted_from_name,Extracted parameters with uncertain training tokens,,
gemma_2_27b,Google,,27000000000.0,5.25e+22,medium,scaling_laws,Benchmark Based: 3.27e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 27,000,000,000 params × 324,000,000,000 tokens = 5.25e+22 FLOP (Mid-era model: 27B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.802802,,extracted_from_name,Known parameters with estimated training tokens,,
mixtral_8x22b_instruct,Mistral,,22000000000.0,5.23e+22,medium,scaling_laws,Benchmark Based: 2.13e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 22,000,000,000 params × 396,000,000,000 tokens = 5.23e+22 FLOP (Specialized model: 22B params * 18 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.975208,,extracted_from_name,Known parameters with estimated training tokens,allowed,
mixtral_8x22b,Mistral,,22000000000.0,4.36e+22,low,scaling_laws,Benchmark Based: 2.20e+25 (Low),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 22,000,000,000 params × 330,000,000,000 tokens = 4.36e+22 FLOP (Generic estimate: 22B params * 15 tokens/param)",https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-04T19:46:43.996389,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
mistral_small_24b,Mistral,,24000000000.0,4.15e+22,medium,scaling_laws,Benchmark Based: 3.13e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 24,000,000,000 params × 288,000,000,000 tokens = 4.15e+22 FLOP (Mid-era model: 24B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.970394,,extracted_from_name,Known parameters with estimated training tokens,allowed,
mistral_small_3.1_24b,Mistral,,24000000000.0,4.15e+22,medium,scaling_laws,Benchmark Based: 3.31e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 24,000,000,000 params × 288,000,000,000 tokens = 4.15e+22 FLOP (Mid-era model: 24B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.968188,,extracted_from_name,Known parameters with estimated training tokens,allowed,
reka_flash_21b,Reka AI,,21000000000.0,3.97e+22,low,scaling_laws,Benchmark Based: 2.97e+25 (Low),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 21,000,000,000 params × 315,000,000,000 tokens = 3.97e+22 FLOP (Generic estimate: 21B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.975503,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
reka_flash_21b_online,Reka AI,,21000000000.0,3.97e+22,low,scaling_laws,Benchmark Based: 3.01e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 21,000,000,000 params × 315,000,000,000 tokens = 3.97e+22 FLOP (Generic estimate: 21B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.974600,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
internlm2.5_20b,InternLM,,20000000000.0,3.6e+22,low,scaling_laws,Benchmark Based: 2.84e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 20,000,000,000 params × 300,000,000,000 tokens = 3.60e+22 FLOP (Generic estimate: 20B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.822379,,extracted_from_name,Extracted parameters with uncertain training tokens,,
internlm2_5_20b,InternLM,,20000000000.0,3.60e+22,low,scaling_laws,Benchmark Based: 2.76e+25 (Low),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 20,000,000,000 params × 300,000,000,000 tokens = 3.60e+22 FLOP (Generic estimate: 20B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.977056,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
llama_4_maverick_17b_128e,Meta,,17000000000.0,3.47e+22,medium,scaling_laws,Benchmark Based: 4.64e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 17,000,000,000 params × 340,000,000,000 tokens = 3.47e+22 FLOP (Modern model: 17B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.964079,,extracted_from_name,Known parameters with estimated training tokens,allowed,
llama_4_scout_17b_16e,Meta,,17000000000.0,3.47e+22,medium,scaling_laws,Benchmark Based: 3.95e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 17,000,000,000 params × 340,000,000,000 tokens = 3.47e+22 FLOP (Modern model: 17B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.965540,,extracted_from_name,Known parameters with estimated training tokens,allowed,
qwen1.5_14b,Alibaba,,14000000000.0,1.88e+22,medium,scaling_laws,Benchmark Based: 2.60e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 14,000,000,000 params × 224,000,000,000 tokens = 1.88e+22 FLOP (Chinese model: 14B params * 16 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.977150,,extracted_from_name,Known parameters with estimated training tokens,allowed,
qwen_14b,Alibaba,,14000000000.0,1.88e+22,medium,scaling_laws,Benchmark Based: 2.37e+25 (Low),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 14,000,000,000 params × 224,000,000,000 tokens = 1.88e+22 FLOP (Chinese model: 14B params * 16 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.983612,,extracted_from_name,Known parameters with estimated training tokens,allowed,
rwkv_4_raven_14b,RWKV,,14000000000.0,1.76e+22,low,scaling_laws,Benchmark Based: 1.82e+25 (Low),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 14,000,000,000 params × 210,000,000,000 tokens = 1.76e+22 FLOP (Generic estimate: 14B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.985787,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
gemma_3_12b,Google,,12000000000.0,1.73e+22,medium,scaling_laws,Benchmark Based: 4.07e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 12,000,000,000 params × 240,000,000,000 tokens = 1.73e+22 FLOP (Modern model: 12B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.794507,,extracted_from_name,Known parameters with estimated training tokens,,
baichuan2_13b,Unknown,,13000000000.0,1.62e+22,medium,scaling_laws,,high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 13,000,000,000 params × 208,000,000,000 tokens = 1.62e+22 FLOP (Chinese model: 13B params * 16 tokens/param)",https://llmbench.github.io/ChineseSimpleQA/ (ChineseSimpleQA - Question answering benchmark for Chinese LLMs),,2025-08-04T16:03:15.478266,,extracted_from_name,Known parameters with estimated training tokens,allowed,
alpaca_13b,Stanford,,13000000000.0,1.52e+22,low,scaling_laws,Benchmark Based: 1.93e+25 (Low),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 13,000,000,000 params × 195,000,000,000 tokens = 1.52e+22 FLOP (Generic estimate: 13B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.985569,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
gpt4all_13b_snoozy,Nomic AI,,13000000000.0,1.52e+22,low,scaling_laws,Benchmark Based: 1.95e+25 (Low),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 13,000,000,000 params × 195,000,000,000 tokens = 1.52e+22 FLOP (Generic estimate: 13B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.985502,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
koala_13b,UC Berkeley,,13000000000.0,1.52e+22,low,scaling_laws,Benchmark Based: 1.97e+25 (Low),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 13,000,000,000 params × 195,000,000,000 tokens = 1.52e+22 FLOP (Generic estimate: 13B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.985431,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
vicuna_13b,LMSYS,,13000000000.0,1.52e+22,low,scaling_laws,Benchmark Based: 2.40e+25 (Low),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 13,000,000,000 params × 195,000,000,000 tokens = 1.52e+22 FLOP (Generic estimate: 13B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.983246,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
wizardlm_13b,Microsoft,,13000000000.0,1.52e+22,low,scaling_laws,Benchmark Based: 2.14e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 13,000,000,000 params × 195,000,000,000 tokens = 1.52e+22 FLOP (Generic estimate: 13B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.815515,,extracted_from_name,Extracted parameters with uncertain training tokens,,
llama_3.2_11b_vision,Meta,,11000000000.0,1.45e+22,medium,scaling_laws,Benchmark Based: 1.36e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 11,000,000,000 params × 220,000,000,000 tokens = 1.45e+22 FLOP (Modern model: 11B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.991931,,extracted_from_name,Known parameters with estimated training tokens,allowed,
dolly_v2_12b,Databricks,,12000000000.0,1.30e+22,low,scaling_laws,Benchmark Based: 1.48e+25 (Low),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 12,000,000,000 params × 180,000,000,000 tokens = 1.30e+22 FLOP (Generic estimate: 12B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.986258,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
oasst_pythia_12b,OpenAssistant,,12000000000.0,1.30e+22,low,scaling_laws,Benchmark Based: 1.70e+25 (Low),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 12,000,000,000 params × 180,000,000,000 tokens = 1.30e+22 FLOP (Generic estimate: 12B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.985955,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
pixtral_12b,Mistral,,12000000000.0,1.30e+22,low,scaling_laws,Benchmark Based: 1.27e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 12,000,000,000 params × 180,000,000,000 tokens = 1.30e+22 FLOP (Generic estimate: 12B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.991491,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
solar_10.7b_instruct,Upstage AI,,10700000000.0,1.24e+22,medium,scaling_laws,Benchmark Based: 2.23e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 10,700,000,000 params × 192,600,000,000 tokens = 1.24e+22 FLOP (Specialized model: 11B params * 18 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.814630,,extracted_from_name,Known parameters with estimated training tokens,,
llama_2_13b,Meta,,13000000000.0,1.22e+22,medium,scaling_laws,Benchmark Based: 1.57e+25 (Low),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 13,000,000,000 params × 156,000,000,000 tokens = 1.22e+22 FLOP (Mid-era model: 13B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.983042,,extracted_from_name,Known parameters with estimated training tokens,allowed,
yi_coder_9b,01 AI,,9000000000.0,8.75e+21,medium,scaling_laws,,high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 9,000,000,000 params × 162,000,000,000 tokens = 8.75e+21 FLOP (Specialized model: 9B params * 18 tokens/param)",https://github.com/openai/open-agent-leaderboard (Open Agent Leaderboard - Multi-task agent performance evaluation),,2025-08-04T16:03:15.513596,,extracted_from_name,Known parameters with estimated training tokens,allowed,
llama_13b,Meta,,13000000000.0,8.11e+21,low,scaling_laws,Benchmark Based: 1.49e+25 (Low),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 13,000,000,000 params × 104,000,000,000 tokens = 8.11e+21 FLOP (Early era model: 13B params * 8 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.986180,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
llama_3.1_tulu_3_8b,Ai2,,8000000000.0,7.68e+21,medium,scaling_laws,Benchmark Based: 3.04e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 8,000,000,000 params × 160,000,000,000 tokens = 7.68e+21 FLOP (Modern model: 8B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.808948,,extracted_from_name,Known parameters with estimated training tokens,,
gemma_2_9b,Google,,9000000000.0,5.83e+21,medium,scaling_laws,Benchmark Based: 3.09e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 9,000,000,000 params × 108,000,000,000 tokens = 5.83e+21 FLOP (Mid-era model: 9B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.807089,,extracted_from_name,Known parameters with estimated training tokens,,
gemma_2_9b_it_simpo,Princeton,,9000000000.0,5.83e+21,medium,scaling_laws,Benchmark Based: 3.21e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 9,000,000,000 params × 108,000,000,000 tokens = 5.83e+21 FLOP (Mid-era model: 9B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.802981,,extracted_from_name,Known parameters with estimated training tokens,,
aya_expanse_8b,Cohere,,8000000000.0,5.76e+21,low,scaling_laws,Benchmark Based: 2.97e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 8,000,000,000 params × 120,000,000,000 tokens = 5.76e+21 FLOP (Generic estimate: 8B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.822242,,extracted_from_name,Extracted parameters with uncertain training tokens,,
c4ai_aya_expanse_8b,Cohere,,8000000000.0,5.76e+21,low,scaling_laws,Benchmark Based: 2.93e+25 (Low),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 8,000,000,000 params × 120,000,000,000 tokens = 5.76e+21 FLOP (Generic estimate: 8B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.975913,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
gemini_1.5_flash_8b_001,Google,,8000000000.0,5.76e+21,low,scaling_laws,Benchmark Based: 2.69e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 8,000,000,000 params × 120,000,000,000 tokens = 5.76e+21 FLOP (Generic estimate: 8B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.971472,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
granite_3.0_8b,IBM,,8000000000.0,5.76e+21,low,scaling_laws,Benchmark Based: 2.42e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 8,000,000,000 params × 120,000,000,000 tokens = 5.76e+21 FLOP (Generic estimate: 8B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.810609,,extracted_from_name,Extracted parameters with uncertain training tokens,,
granite_3.1_8b,IBM,,8000000000.0,5.76e+21,low,scaling_laws,Benchmark Based: 2.85e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 8,000,000,000 params × 120,000,000,000 tokens = 5.76e+21 FLOP (Generic estimate: 8B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.809599,,extracted_from_name,Extracted parameters with uncertain training tokens,,
ministral_8b,Mistral,,8000000000.0,5.76e+21,low,scaling_laws,Benchmark Based: 3.11e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 8,000,000,000 params × 120,000,000,000 tokens = 5.76e+21 FLOP (Generic estimate: 8B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.808263,,extracted_from_name,Extracted parameters with uncertain training tokens,,
mixtral_8x7b_instruct,Mistral,,7000000000.0,5.29e+21,medium,scaling_laws,Benchmark Based: 1.65e+25 (Low),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 126,000,000,000 tokens = 5.29e+21 FLOP (Specialized model: 7B params * 18 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.976891,,extracted_from_name,Known parameters with estimated training tokens,allowed,
qwen1.5_7b,Alibaba,,7000000000.0,4.70e+21,medium,scaling_laws,Benchmark Based: 2.34e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 112,000,000,000 tokens = 4.70e+21 FLOP (Chinese model: 7B params * 16 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.983168,,extracted_from_name,Known parameters with estimated training tokens,allowed,
gemma_1.1_7b,Google,,7000000000.0,4.41e+21,low,scaling_laws,Benchmark Based: 2.37e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.813290,,extracted_from_name,Extracted parameters with uncertain training tokens,,
gemma_7b,Google,,7000000000.0,4.41e+21,low,scaling_laws,Benchmark Based: 2.36e+25 (Low),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.983695,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
molmo_7b_d,Ai2,,7000000000.0,4.41e+21,low,scaling_laws,,high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.823516,,extracted_from_name,Extracted parameters with uncertain training tokens,,
mpt_7b,MosaicML,,7000000000.0,4.41e+21,low,scaling_laws,Benchmark Based: 1.92e+25 (Low),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.985642,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
nous_hermes_2_mixtral_8x7b_dpo,NousResearch,,7000000000.0,4.41e+21,low,scaling_laws,Benchmark Based: 2.41e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.814107,,extracted_from_name,Extracted parameters with uncertain training tokens,,
olmo_7b,Allen AI,,7000000000.0,4.41e+21,low,scaling_laws,Benchmark Based: 2.02e+25 (Low),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.985356,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
stablelm_tuned_alpha_7b,Stability AI,,7000000000.0,4.41e+21,low,scaling_laws,Benchmark Based: 1.40e+25 (Low),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.986335,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
starling_lm_7b,Nexusflow,,7000000000.0,4.41e+21,low,scaling_laws,Benchmark Based: 2.64e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.813886,,extracted_from_name,Extracted parameters with uncertain training tokens,,
starling_lm_7b_alpha,UC Berkeley,,7000000000.0,4.41e+21,low,scaling_laws,Benchmark Based: 2.40e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.814465,,extracted_from_name,Extracted parameters with uncertain training tokens,,
stripedhyena_nous_7b,Together AI,,7000000000.0,4.41e+21,low,scaling_laws,Benchmark Based: 2.27e+25 (Low),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.984682,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
vicuna_7b,LMSYS,,7000000000.0,4.41e+21,low,scaling_laws,Benchmark Based: 2.24e+25 (Low),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.984746,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
zephyr_7b,HuggingFace,,7000000000.0,4.41e+21,low,scaling_laws,Benchmark Based: 2.13e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.817921,,extracted_from_name,Extracted parameters with uncertain training tokens,,
zephyr_7b_alpha,HuggingFace,,7000000000.0,4.41e+21,low,scaling_laws,Benchmark Based: 2.32e+25 (Low),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 105,000,000,000 tokens = 4.41e+21 FLOP (Generic estimate: 7B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.983947,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
chatglm2_6b,Tsinghua,,6000000000.0,3.89e+21,medium,scaling_laws,Benchmark Based: 1.76e+25 (Low),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 6,000,000,000 params × 108,000,000,000 tokens = 3.89e+21 FLOP (Specialized model: 6B params * 18 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.985854,,extracted_from_name,Known parameters with estimated training tokens,allowed,
chatglm3_6b,Tsinghua,,6000000000.0,3.89e+21,medium,scaling_laws,Benchmark Based: 1.88e+25 (Low),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 6,000,000,000 params × 108,000,000,000 tokens = 3.89e+21 FLOP (Specialized model: 6B params * 18 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.985716,,extracted_from_name,Known parameters with estimated training tokens,allowed,
chatglm_6b,Tsinghua,,6000000000.0,3.89e+21,medium,scaling_laws,Benchmark Based: 1.62e+25 (Low),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 6,000,000,000 params × 108,000,000,000 tokens = 3.89e+21 FLOP (Specialized model: 6B params * 18 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.986034,,extracted_from_name,Known parameters with estimated training tokens,allowed,
dolphin_2.2.1_mistral_7b,Cognitive,,7000000000.0,3.53e+21,medium,scaling_laws,Benchmark Based: 2.15e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 84,000,000,000 tokens = 3.53e+21 FLOP (Mid-era model: 7B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.814908,,extracted_from_name,Known parameters with estimated training tokens,,
mistral_7b,Mistral,,7000000000.0,3.53e+21,medium,scaling_laws,Benchmark Based: 2.21e+25 (Low),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 84,000,000,000 tokens = 3.53e+21 FLOP (Mid-era model: 7B params * 12 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.984981,,extracted_from_name,Known parameters with estimated training tokens,allowed,
mistral_7b_instruct,Mistral,,7000000000.0,3.53e+21,medium,scaling_laws,Benchmark Based: 1.28e+25 (Low),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 84,000,000,000 tokens = 3.53e+21 FLOP (Mid-era model: 7B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.982398,,extracted_from_name,Known parameters with estimated training tokens,allowed,
openhermes_2.5_mistral_7b,NousResearch,,7000000000.0,3.53e+21,medium,scaling_laws,Benchmark Based: 2.29e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 84,000,000,000 tokens = 3.53e+21 FLOP (Mid-era model: 7B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.812692,,extracted_from_name,Known parameters with estimated training tokens,,
qwen2_vl_7b,Alibaba,,7000000000.0,3.53e+21,medium,scaling_laws,,high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 7,000,000,000 params × 84,000,000,000 tokens = 3.53e+21 FLOP (Mid-era model: 7B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.991808,,extracted_from_name,Known parameters with estimated training tokens,allowed,
gemma_3_4b,Google,,4000000000.0,1.92e+21,medium,scaling_laws,Benchmark Based: 3.69e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 4,000,000,000 params × 80,000,000,000 tokens = 1.92e+21 FLOP (Modern model: 4B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.801257,,extracted_from_name,Known parameters with estimated training tokens,,
gemma_3n_e4b,Google,,4000000000.0,1.92e+21,medium,scaling_laws,Benchmark Based: 3.87e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 4,000,000,000 params × 80,000,000,000 tokens = 1.92e+21 FLOP (Modern model: 4B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.799367,,extracted_from_name,Known parameters with estimated training tokens,,
qwen1.5_4b,Alibaba,,4000000000.0,1.54e+21,medium,scaling_laws,Benchmark Based: 2.07e+25 (Low),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 4,000,000,000 params × 64,000,000,000 tokens = 1.54e+21 FLOP (Chinese model: 4B params * 16 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.985280,,extracted_from_name,Known parameters with estimated training tokens,allowed,
llama_3.2_3b,Meta,,3000000000.0,1.08e+21,medium,scaling_laws,Benchmark Based: 1.56e+25 (Low),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 3,000,000,000 params × 60,000,000,000 tokens = 1.08e+21 FLOP (Modern model: 3B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.981258,,extracted_from_name,Known parameters with estimated training tokens,allowed,
fastchat_t5_3b,LMSYS,,3000000000.0,9.72e+20,medium,scaling_laws,Benchmark Based: 1.57e+25 (Low),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 3,000,000,000 params × 54,000,000,000 tokens = 9.72e+20 FLOP (Specialized model: 3B params * 18 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.986108,,extracted_from_name,Known parameters with estimated training tokens,allowed,
gemma_1.1_2b,Google,,2000000000.0,3.60e+20,low,scaling_laws,Benchmark Based: 2.20e+25 (Low),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 2,000,000,000 params × 30,000,000,000 tokens = 3.60e+20 FLOP (Generic estimate: 2B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.985130,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
granite_3.0_2b,IBM,,2000000000.0,3.6e+20,low,scaling_laws,Benchmark Based: 2.33e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 2,000,000,000 params × 30,000,000,000 tokens = 3.60e+20 FLOP (Generic estimate: 2B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.815024,,extracted_from_name,Extracted parameters with uncertain training tokens,,
granite_3.1_2b,IBM,,2000000000.0,3.6e+20,low,scaling_laws,Benchmark Based: 2.68e+25 (Medium),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 2,000,000,000 params × 30,000,000,000 tokens = 3.60e+20 FLOP (Generic estimate: 2B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.812294,,extracted_from_name,Extracted parameters with uncertain training tokens,,
gemma_2_2b,Google,,2000000000.0,2.88e+20,medium,scaling_laws,Benchmark Based: 2.66e+25 (Medium),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 2,000,000,000 params × 24,000,000,000 tokens = 2.88e+20 FLOP (Mid-era model: 2B params * 12 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.810154,,extracted_from_name,Known parameters with estimated training tokens,,
gemma_2b,Google,,2000000000.0,2.88e+20,medium,scaling_laws,Benchmark Based: 2.08e+25 (Low),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 2,000,000,000 params × 24,000,000,000 tokens = 2.88e+20 FLOP (Mid-era model: 2B params * 12 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.985207,,extracted_from_name,Known parameters with estimated training tokens,allowed,
smollm2_1.7b,HuggingFace,,1700000000.0,2.60e+20,low,scaling_laws,Benchmark Based: 2.32e+25 (Low),high_confidence_below_1e25,uncertain,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 1,700,000,000 params × 25,500,000,000 tokens = 2.60e+20 FLOP (Generic estimate: 2B params * 15 tokens/param)",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-04T19:46:43.983866,,extracted_from_name,Extracted parameters with uncertain training tokens,allowed,
llama_3.2_1b,Meta,,1000000000.0,1.20e+20,medium,scaling_laws,Benchmark Based: 1.15e+25 (Low),high_confidence_below_1e25,likely_below_1e25,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 1,000,000,000 params × 20,000,000,000 tokens = 1.20e+20 FLOP (Modern model: 1B params * 20 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-04T19:46:43.984900,,extracted_from_name,Known parameters with estimated training tokens,allowed,
