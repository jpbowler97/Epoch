model,developer,release_date,parameters,parameter_source,training_flop,confidence,confidence_explanation,estimation_method,alternative_methods,threshold_classification,reasoning,sources,verified,last_updated,notes,blacklist_status
claude_opus_4,Anthropic,,,,1.5e+26,low,Speculative research estimate,epoch_estimate,Benchmark Based: 5.04e+25 (Low),,https://epoch.ai/data-insights/models-over-1e25-flop: Speculative estimate for next-gen Claude,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.219934,,allowed
gemini_2.5_pro,Google,,,,4.86e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Benchmark-based estimation - official parameters not disclosed,https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T18:13:34.218862,,allowed
gpt_5_mini,OpenAI,,,,7.329999999999999e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 2 benchmarks: aai_score: 9.49e+25 (Low); mmlu_pro_score: 5.17e+25 (Low) → weighted average: 7.33e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.264934,,allowed
grok_4,xAI,,,,6.749999999999999e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 5.30e+25 (Low); coding_score: 5.20e+25 (Low); aai_score: 1.07e+26 (Low); mmlu_pro_score: 5.78e+25 (Low) → weighted average: 6.75e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.219466,,allowed
gpt_4.5_preview,OpenAI,,,,6.4e+25,low,Speculative research estimate,epoch_estimate,Benchmark Based: 4.75e+25 (Low),,https://epoch.ai/data-insights/models-over-1e25-flop: Low-precision estimate for GPT-4.5,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.219346,,allowed
gemini_2.0_flash,Google,,,,6.000000000000001e+25,low,Distant benchmark interpolation or single source,benchmark_based,,high_confidence_above_1e25,Benchmark-based estimation - official parameters not disclosed,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),y,2025-07-31T18:56:49.505562,,
deepseek_coder,DeepSeek,,671000000000.0,known_specification:deepseek,5.959999999999999e+25,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 3.26e+25 (Medium),high_confidence_above_1e25,"Known model specification 'deepseek': Chinchilla scaling law: 6 × 671,000,000,000 params × 14,800,000,000,000 tokens = 5.96e+25 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-01T21:13:48.807190,,
deepseek_v3,DeepSeek,,671000000000.0,known_specification:deepseek_v3,5.959999999999999e+25,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 4.07e+25 (Low),,"Known model specification 'deepseek_v3': Chinchilla scaling law: 6 × 671,000,000,000 params × 14,800,000,000,000 tokens = 5.96e+25 FLOP",https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T18:13:34.221217,,allowed
o1,OpenAI,,,,5.559999999999999e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 4.55e+25 (Medium); coding_score: 4.54e+25 (Medium); aai_score: 8.88e+25 (Low); mmlu_pro_score: 5.38e+25 (Medium) → weighted average: 5.56e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),y,2025-08-04T20:23:58.155429,Manual review - confirmed above 1e25 FLOP. Reason: Known large reasoning model,allowed
gpt_5_nano,OpenAI,,,,5.55e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 2 benchmarks: aai_score: 6.76e+25 (Low); mmlu_pro_score: 4.34e+25 (Low) → weighted average: 5.55e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.270924,,allowed
gpt_5,OpenAI,,,,5.47e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,,Multi-benchmark estimation from 5 benchmarks: superclue_overall: 5.94e+25 (Medium); superclue_math: 5.70e+25 (Medium); superclue_reasoning: 2.77e+25 (Medium); superclue_code: 6.24e+25 (Medium); superclue_agents: 6.69e+25 (Medium) → weighted average: 5.47e+25 FLOP,https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),y,2025-08-11T21:33:30.642316,Manual review - confirmed above 1e25 FLOP. Reason: I just know GPT5 must be big!,allowed
o3,OpenAI,,,,5.3299999999999995e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 5 benchmarks: superclue_overall: 5.64e+25 (Low); superclue_math: 6.62e+25 (Low); superclue_reasoning: 3.52e+25 (Low); superclue_code: 5.53e+25 (Low); superclue_agents: 5.36e+25 (Low) → weighted average: 5.33e+25 FLOP,https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T18:13:34.219065,,allowed
grok_3,xAI,,,,4.99e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 5.15e+25 (Low); coding_score: 5.17e+25 (Low); aai_score: 4.90e+25 (Low); mmlu_pro_score: 4.73e+25 (Low) → weighted average: 4.99e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.220059,,allowed
gpt_4.1,OpenAI,,,,4.84e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 4.68e+25 (Low); coding_score: 4.72e+25 (Low); aai_score: 5.12e+25 (Low); mmlu_pro_score: 4.83e+25 (Low) → weighted average: 4.84e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.220338,,allowed
gemini_2.5_flash,Google,,,,5.76e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Benchmark-based estimation - official parameters not disclosed,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.220219,,allowed
claude_sonnet_4,Anthropic,,,,4.7699999999999994e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 4.28e+25 (Low); coding_score: 4.60e+25 (Low); aai_score: 4.90e+25 (Low); mmlu_pro_score: 5.31e+25 (Low) → weighted average: 4.77e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.221397,,allowed
chatgpt_4o,OpenAI,,,,4.7e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 5.19e+25 (Low); coding_score: 5.11e+25 (Low); aai_score: 3.71e+25 (Low); mmlu_pro_score: 4.79e+25 (Low) → weighted average: 4.70e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.219207,,allowed
claude_opus_4_thinking_16k,Anthropic,,,,4.5799999999999996e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,"Benchmark-based (lmarena_score): 1421.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 4.58e+25 FLOP",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T18:13:34.219559,,allowed
kimi_k2_preview,Moonshot,,,,4.55e+25,medium,,benchmark_based,,not_sure,"Benchmark-based (openlm_arena_elo): Benchmark-based estimation: ELO 1380.0 vs reference llama_405b (ELO 1300, 3.80e+25 FLOP) with power law scaling α=3.0 = 4.55e+25 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),y,2025-08-01T15:52:05.757110,Manual review - confirmed above 1e25 FLOP. Reason: Example reasoning,
claude_3_7_sonnet,Anthropic,,,,4.47e+25,medium,,benchmark_based,,not_sure,"Benchmark-based (lmarena_score): Benchmark-based estimation: ELO 1372.0 vs reference llama_405b (ELO 1300, 3.80e+25 FLOP) with power law scaling α=3.0 = 4.47e+25 FLOP",LMArena Manual Data Collection (CSV file with manually collected leaderboard data),y,2025-08-01T17:43:00.800819,Manual review - confirmed above 1e25 FLOP. Reason: This is a big model... pretty sure it's over 1e25 flop,
gemini_2.0_pro,Google,,,,4.439999999999999e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 4.87e+25 (Low); coding_score: 4.72e+25 (Low); aai_score: 3.35e+25 (Low); mmlu_pro_score: 4.82e+25 (Low) → weighted average: 4.44e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.264235,,allowed
claude_sonnet_4_thinking_32k,Anthropic,,,,4.379999999999999e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,"Benchmark-based (lmarena_score): 1400.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 4.38e+25 FLOP",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T18:13:34.220423,,allowed
gemini_2.5_flash_lite,Google,,,,4.32e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 2 benchmarks: aai_score: 4.49e+25 (Low); mmlu_pro_score: 4.16e+25 (Low) → weighted average: 4.32e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.270158,,allowed
gpt_4.1_mini,OpenAI,,,,4.32e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 4.27e+25 (Low); coding_score: 4.45e+25 (Low); aai_score: 4.09e+25 (Low); mmlu_pro_score: 4.47e+25 (Low) → weighted average: 4.32e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.222469,,allowed
qwen3_coder_480b,Alibaba,,480000000000.0,known_specification:qwen3_coder_480b,4.32e+25,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 4.63e+25 (Low),,"Known model specification 'qwen3_coder_480b': Chinchilla scaling law: 6 × 480,000,000,000 params × 15,000,000,000,000 tokens = 4.32e+25 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.220993,,allowed
claude_3_7_sonnet_thinking_32k,Anthropic,,,,4.26e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,"Benchmark-based (lmarena_score): 1387.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 4.26e+25 FLOP",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T18:13:34.221520,,allowed
o1_preview,OpenAI,,,,4.24e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,"Benchmark-based (lmarena_score): 1385.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 4.24e+25 FLOP",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T18:13:34.221640,,allowed
mistral_medium_3,Mistral,,,,4.2299999999999994e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 4.58e+25 (Low); coding_score: 4.63e+25 (Low); aai_score: 3.52e+25 (Low); mmlu_pro_score: 4.17e+25 (Low) → weighted average: 4.23e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.265691,,allowed
o1_mini,OpenAI,,,,4.18e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 4.10e+25 (Low); coding_score: 4.42e+25 (Low); aai_score: 4.28e+25 (Low); mmlu_pro_score: 3.93e+25 (Low) → weighted average: 4.18e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.228244,,allowed
claude_opus_4_reasoning,Anthropic,,,,4.1e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 5 benchmarks: superclue_overall: 4.43e+25 (Low); superclue_math: 3.09e+25 (Low); superclue_reasoning: 1.83e+25 (Low); superclue_code: 4.99e+25 (Low); superclue_agents: 6.18e+25 (Low) → weighted average: 4.10e+25 FLOP,https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T18:13:34.276579,,allowed
gemini_2.0_flash_001,Google,,,,4.07e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,"Benchmark-based (lmarena_score): 1366.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 4.07e+25 FLOP",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T18:13:34.223122,,allowed
claude_3.7_sonnet,Anthropic,,,,4.0199999999999995e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 3.93e+25 (Low); coding_score: 4.18e+25 (Low); aai_score: 3.17e+25 (Low); mmlu_pro_score: 4.79e+25 (Low) → weighted average: 4.02e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.270755,,allowed
qwen2.5_max,Alibaba,,,,3.9799999999999995e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 4.56e+25 (Low); coding_score: 4.49e+25 (Low); aai_score: 2.68e+25 (Low); mmlu_pro_score: 4.20e+25 (Low) → weighted average: 3.98e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.222848,,allowed
claude_3_5_sonnet,Anthropic,,,,3.8399999999999997e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,"Benchmark-based (lmarena_score): 1340.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 3.84e+25 FLOP",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T18:13:34.223022,,allowed
gpt_4o,OpenAI,,1760000000000.0,known_specification:gpt_4o,3.7999999999999996e+25,medium,Reliable research estimate from industry analysis,epoch_estimate,Scaling Laws: 1.37e+26 (Medium); Benchmark Based: 3.88e+25 (Low),,https://epoch.ai/data-insights/models-over-1e25-flop: Low-precision estimate from OpenAI patterns,https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T18:13:34.227215,,allowed
llama_3.1_405b,Meta,,405000000000.0,known_specification:llama_3.1_405b,3.7999999999999996e+25,high,Official disclosure or high-precision research estimate,epoch_estimate,Scaling Laws: 3.65e+25 (High),,https://epoch.ai/data-insights/models-over-1e25-flop: High-precision estimate from Meta disclosure,https://gair-nlp.github.io/OlympicArena (OlympicArena - Chinese LLM benchmark across STEM subjects),,2025-08-15T18:13:34.263281,,allowed
gemini_advanced,Google,,,,3.7699999999999996e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,"Benchmark-based (lmarena_score): 1332.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 3.77e+25 FLOP",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T18:13:34.228948,,allowed
amazon_nova_chat_05_14,Amazon,,,,3.7299999999999995e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 4.14e+25 (Low); coding_score: 4.14e+25 (Low); aai_score: 2.84e+25 (Low); mmlu_pro_score: 3.81e+25 (Low) → weighted average: 3.73e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.270576,,allowed
grok_2_mini_08_13,xAI,,,,3.7e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.77e+25 (Low); coding_score: 3.63e+25 (Low) → weighted average: 3.70e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.271784,,allowed
magistral_medium,Mistral,,,,3.7e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 3.51e+25 (Low); coding_score: 3.87e+25 (Low); aai_score: 3.35e+25 (Low); mmlu_pro_score: 4.08e+25 (Low) → weighted average: 3.70e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.234002,,allowed
gemini_1.5_pro_002,Google,,,,3.68e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 4.11e+25 (Low); coding_score: 3.91e+25 (Low); aai_score: 2.68e+25 (Low); mmlu_pro_score: 4.04e+25 (Low) → weighted average: 3.68e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.224025,,allowed
gemini_1.5_pro_001,Google,,,,3.67e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,"Benchmark-based (lmarena_score): 1320.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 3.67e+25 FLOP",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T18:13:34.230751,,allowed
qwen_max,Alibaba,,,,3.67e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 5 benchmarks: superclue_overall: 4.02e+25 (Low); superclue_math: 3.91e+25 (Low); superclue_reasoning: 1.98e+25 (Low); superclue_code: 4.28e+25 (Low); superclue_agents: 4.15e+25 (Low) → weighted average: 3.67e+25 FLOP,https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T18:13:34.231480,,allowed
amazon_nova_experimental_chat_05_14,Amazon,,,,3.66e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,"Benchmark-based (lmarena_score): 1318.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 3.66e+25 FLOP",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T18:13:34.230873,,allowed
claude_3_5_haiku,Anthropic,,,,3.65e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,"Benchmark-based (lmarena_score): 1317.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 3.65e+25 FLOP",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T18:13:34.232311,,allowed
qwen2.5_plus,Alibaba,,,,3.6299999999999998e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,"Benchmark-based (lmarena_score): 1315.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 3.63e+25 FLOP",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T18:13:34.231858,,allowed
claude_3.5_sonnet,Anthropic,,,,3.5999999999999997e+25,medium,,company_disclosure,,not_sure,Epoch AI: Low-precision estimate from benchmarks,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),y,2025-07-31T18:56:49.506343,,
grok_2_mini,xAI,,,,3.5699999999999997e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,"Benchmark-based (lmarena_score): 1307.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 3.57e+25 FLOP",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T18:13:34.234264,,allowed
gpt_4_preview,OpenAI,,,,3.5499999999999996e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.63e+25 (Low); coding_score: 3.48e+25 (Low) → weighted average: 3.55e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.233002,,allowed
gemini_2.0_flash_lite,Google,,,,3.5399999999999996e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 4.21e+25 (Low); coding_score: 4.15e+25 (Low); aai_score: 2.09e+25 (Low); mmlu_pro_score: 3.70e+25 (Low) → weighted average: 3.54e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.223823,,allowed
mistral_small,Mistral,,,,3.5399999999999996e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 4.25e+25 (Low); coding_score: 4.37e+25 (Low); aai_score: 2.37e+25 (Low); mmlu_pro_score: 3.17e+25 (Low) → weighted average: 3.54e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.224326,,allowed
qwen_plus,Alibaba,,,,3.4599999999999995e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.42e+25 (Low); coding_score: 3.49e+25 (Low) → weighted average: 3.46e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.225024,,allowed
deepseek_v2_api,DeepSeek,,,,3.44e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 3.41e+25 (Low); coding_score: 3.47e+25 (Low) → weighted average: 3.44e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.272100,,allowed
gemini_1.5_flash_001,Google,,,,3.38e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,"Benchmark-based (lmarena_score): 1284.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 3.38e+25 FLOP",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T18:13:34.236451,,allowed
grok_2_08_13,xAI,,,,3.2699999999999996e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 3.98e+25 (Low); coding_score: 3.79e+25 (Low); aai_score: 1.82e+25 (Low); mmlu_pro_score: 3.51e+25 (Low) → weighted average: 3.27e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.271372,,allowed
gpt_4.1_nano,OpenAI,,,,3.18e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 3.81e+25 (Low); coding_score: 3.92e+25 (Low); aai_score: 2.09e+25 (Low); mmlu_pro_score: 2.90e+25 (Low) → weighted average: 3.18e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.230250,,allowed
amazon_nova_pro,Amazon,,,,3.12e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 3.59e+25 (Low); coding_score: 3.65e+25 (Low); aai_score: 1.95e+25 (Low); mmlu_pro_score: 3.29e+25 (Low) → weighted average: 3.12e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.235580,,allowed
gpt_4_turbo,OpenAI,,,,3.12e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 3.70e+25 (Low); coding_score: 3.64e+25 (Low); aai_score: 1.82e+25 (Low); mmlu_pro_score: 3.33e+25 (Low) → weighted average: 3.12e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.230447,,allowed
gemini_1.5_flash_002,Google,,,,3.1e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 3.84e+25 (Low); coding_score: 3.58e+25 (Low); aai_score: 1.82e+25 (Low); mmlu_pro_score: 3.16e+25 (Low) → weighted average: 3.10e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.233739,,allowed
mistral_large,Mistral,,,,3.0899999999999998e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 3.65e+25 (Low); coding_score: 3.67e+25 (Low); aai_score: 1.69e+25 (Low); mmlu_pro_score: 3.36e+25 (Low) → weighted average: 3.09e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.233891,,allowed
gemini_pro_dev_api,Google,,,,2.9999999999999996e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,"Benchmark-based (lmarena_score): 1234.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 3.00e+25 FLOP",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T18:13:34.242850,,allowed
grok_2,xAI,,,,2.9999999999999996e+25,high,Official disclosure or high-precision research estimate,epoch_estimate,Benchmark Based: 3.77e+25 (Low),,https://epoch.ai/data-insights/models-over-1e25-flop: High-precision estimate from xAI disclosure,CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T18:13:34.229082,,allowed
gpt_4o_mini,OpenAI,,,,2.9799999999999996e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 5 benchmarks: superclue_overall: 3.20e+25 (Low); superclue_math: 2.52e+25 (Low); superclue_reasoning: 1.32e+25 (Low); superclue_code: 3.27e+25 (Low); superclue_agents: 4.59e+25 (Low) → weighted average: 2.98e+25 FLOP,https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T18:13:34.232588,,allowed
gemini_pro,Google,,,,2.91e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,"Benchmark-based (lmarena_score): 1222.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 2.91e+25 FLOP",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T18:13:34.243572,,allowed
claude_1,Anthropic,,,,2.8199999999999998e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 2.92e+25 (Low); coding_score: 2.71e+25 (Low) → weighted average: 2.82e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.273041,,allowed
deepseek_v2.5,DeepSeek,,,,2.8199999999999998e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 5 benchmarks: superclue_overall: 3.05e+25 (Low); superclue_math: 3.12e+25 (Low); superclue_reasoning: 1.20e+25 (Low); superclue_code: 2.95e+25 (Low); superclue_agents: 3.81e+25 (Low) → weighted average: 2.82e+25 FLOP,https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T18:13:34.230046,,allowed
claude_3.5_haiku,Anthropic,,,,2.7599999999999997e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 5 benchmarks: superclue_overall: 2.84e+25 (Low); superclue_math: 1.88e+25 (Low); superclue_reasoning: 8.52e+24 (Low); superclue_code: 3.15e+25 (Low); superclue_agents: 5.07e+25 (Low) → weighted average: 2.76e+25 FLOP,https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T18:13:34.271962,,allowed
amazon_nova_lite,Amazon,,,,2.61e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 3.35e+25 (Low); coding_score: 3.41e+25 (Low); aai_score: 1.45e+25 (Low); mmlu_pro_score: 2.22e+25 (Low) → weighted average: 2.61e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.241245,,allowed
gemini_1.0_pro_001,Google,,,,2.61e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 2.75e+25 (Low); coding_score: 2.47e+25 (Low) → weighted average: 2.61e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.273360,,allowed
gpt_3.5_turbo,OpenAI,,,,2.59e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 2 benchmarks: openlm_arena_elo: 2.63e+25 (Low); coding_score: 2.54e+25 (Low) → weighted average: 2.59e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.243771,,allowed
marco_o1,OpenAI,,,,2.5399999999999998e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 5 benchmarks: superclue_overall: 2.68e+25 (Low); superclue_math: 3.20e+25 (Low); superclue_reasoning: 1.27e+25 (Low); superclue_code: 1.57e+25 (Low); superclue_agents: 4.00e+25 (Low) → weighted average: 2.54e+25 FLOP,https://www.superclueai.com/ (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-15T18:13:34.278971,,allowed
pixtral_large,Mistral,,,,2.4899999999999997e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 2 benchmarks: aai_score: 1.57e+25 (Low); mmlu_pro_score: 3.41e+25 (Low) → weighted average: 2.49e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.274360,,allowed
palm_2,Google,,,,2.37e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,"Benchmark-based (lmarena_score): 1141.0 vs reference llama_3.1_405b (1335.0, 3.80e+25 FLOP) with α=3.0 = 2.37e+25 FLOP",CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T18:13:34.259191,,allowed
claude_3_sonnet,Anthropic,,,,2.3e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 3.27e+25 (Low); coding_score: 3.24e+25 (Low); aai_score: 5.93e+24 (Low); mmlu_pro_score: 2.11e+25 (Low) → weighted average: 2.30e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.236858,,allowed
amazon_nova_micro,Amazon,,,,2.2599999999999997e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 3.20e+25 (Low); coding_score: 3.21e+25 (Low); aai_score: 9.27e+24 (Low); mmlu_pro_score: 1.70e+25 (Low) → weighted average: 2.26e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.241880,,allowed
gemini_1.5_pro,Google,,300000000000.0,known_specification:gemini_1.5_pro,2.16e+25,medium,Known parameters with estimated training tokens,scaling_laws,,,"Known model specification 'gemini_1.5_pro': Chinchilla scaling law: 6 × 300,000,000,000 params × 12,000,000,000,000 tokens = 2.16e+25 FLOP",https://gair-nlp.github.io/OlympicArena (OlympicArena - Chinese LLM benchmark across STEM subjects),,2025-08-15T18:13:34.263095,,allowed
gpt_4,OpenAI,,1760000000000.0,known_specification:gpt_4,2.1e+25,medium,Reliable research estimate from industry analysis,epoch_estimate,Scaling Laws: 1.37e+26 (Medium); Benchmark Based: 3.33e+25 (Low),,https://epoch.ai/data-insights/models-over-1e25-flop: Low-precision estimate from scaling analysis,CSV file with manually collected leaderboard data (LMArena Manual Data Collection),,2025-08-15T18:13:34.236127,,allowed
claude_3_haiku,Anthropic,,,,1.9899999999999997e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 3.09e+25 (Low); coding_score: 3.06e+25 (Low); aai_score: 3.34e+24 (Low); mmlu_pro_score: 1.47e+25 (Low) → weighted average: 1.99e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.240744,,allowed
mistral_medium,Mistral,,,,1.84e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 2.87e+25 (Low); coding_score: 2.79e+25 (Low); aai_score: 2.80e+24 (Low); mmlu_pro_score: 1.40e+25 (Low) → weighted average: 1.84e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.221812,,allowed
claude_3_opus,Anthropic,,175000000000.0,known_specification:claude_3_opus,1.6e+25,medium,Reliable research estimate from industry analysis,epoch_estimate,Scaling Laws: 8.40e+24 (Medium); Benchmark Based: 2.96e+25 (Low),,https://epoch.ai/data-insights/models-over-1e25-flop: Low-precision estimate from industry analysis,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.230639,,allowed
claude_opus,Anthropic,,175000000000.0,known_specification:claude_opus,1.6e+25,medium,Reliable research estimate from industry analysis,epoch_estimate,Scaling Laws: 8.40e+24 (Medium); Benchmark Based: 6.30e+25 (Low),,https://epoch.ai/data-insights/models-over-1e25-flop: Low-precision estimate from industry analysis,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.264049,,allowed
claude_instant_1,Anthropic,,,,1.55e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 4 benchmarks: openlm_arena_elo: 2.61e+25 (Low); coding_score: 2.54e+25 (Low); aai_score: 9.27e+22 (Low); mmlu_pro_score: 1.03e+25 (Low) → weighted average: 1.55e+25 FLOP,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.273569,,allowed
llama_3.1_405b_instruct_bf16,Meta,,405000000000.0,extracted_from_name,1.4799999999999998e+25,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 3.34e+25 (Low),,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 405,000,000,000 params × 6,075,000,000,000 tokens = 1.48e+25 FLOP (Modern large model: 405B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.228510,,allowed
llama_3.1_405b_instruct_fp8,Meta,,405000000000.0,extracted_from_name,1.4799999999999998e+25,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 3.32e+25 (Low),,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 405,000,000,000 params × 6,075,000,000,000 tokens = 1.48e+25 FLOP (Modern large model: 405B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.228772,,allowed
qwen3_235b,Alibaba,,235000000000.0,known_specification:qwen3_235b,1.4099999999999999e+25,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 4.94e+25 (Low),,"Known model specification 'qwen3_235b': Chinchilla scaling law: 6 × 235,000,000,000 params × 10,000,000,000,000 tokens = 1.41e+25 FLOP",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.222715,,allowed
runway_gen_3,Runway,,,,1.0999999999999998e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,,Threshold-based (physics_iq_score): 22.8 > sora (10.0) → assumed >1e25 FLOP (reference model assumed frontier-level),https://physics-iq.github.io/ (Physics-IQ - Benchmark for physical understanding in video generation models),,2025-08-15T18:13:34.275664,,allowed
stable_video_diffusion,Stability AI,,,,1.0999999999999998e+25,medium,Good benchmark match with multiple agreeing sources,benchmark_based,,,Threshold-based (physics_iq_score): 14.8 > sora (10.0) → assumed >1e25 FLOP (reference model assumed frontier-level),https://physics-iq.github.io/ (Physics-IQ - Benchmark for physical understanding in video generation models),,2025-08-15T18:13:34.275801,,allowed
veo_2,Google,,,,1.0999999999999998e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 2 benchmarks: video_arena_elo: 1.10e+25 (Medium); video_quality: 1.10e+25 (Medium) → weighted average: 1.10e+25 FLOP,https://artificialanalysis.ai/text-to-video/arena (Artificial Analysis Video Arena - Text-to-video model rankings),,2025-08-15T18:13:34.279412,,allowed
veo_3_preview,Google,,,,1.0999999999999998e+25,low,Distant benchmark interpolation or single source,benchmark_based,,,Multi-benchmark estimation from 2 benchmarks: video_arena_elo: 1.10e+25 (Medium); video_quality: 1.10e+25 (Medium) → weighted average: 1.10e+25 FLOP,https://artificialanalysis.ai/text-to-video/arena (Artificial Analysis Video Arena - Text-to-video model rankings),,2025-08-15T18:13:34.279299,,allowed
nemotron_4_340b,Nvidia,,340000000000.0,extracted_from_name,1.04e+25,medium,Known parameters with estimated training tokens,scaling_laws,Benchmark Based: 3.23e+25 (Low),,"Parameter-based Chinchilla scaling: Chinchilla scaling law: 6 × 340,000,000,000 params × 5,100,000,000,000 tokens = 1.04e+25 FLOP (Generic estimate: 340B params * 15 tokens/param)",https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.237217,,allowed
step_1o_turbo,StepFun,,,,9.9e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 4.33e+25 (Low),,FLOP estimate capped at 9.9e+24 due to resource constraint policy: Limited computational resources for 1e25+ FLOP training runs,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:34.269776,,allowed
doubao_pro_256k,ByteDance,,,,9.9e+24,low,Distant benchmark interpolation or single source,benchmark_based,Benchmark Based: 4.27e+25 (Medium); Original (uncapped): 4.2699999999999995e+25 FLOP,not_sure,FLOP estimate capped at 9.9e+24 due to developer blacklist policy: Limited disclosure on training methodology and data sources for frontier models. Original estimate: 4.27e+25 FLOP (Multi-benchmark estimation from 5 benchmarks: superclue_overall: 4.16e+25 (Medium); superclue_math: 4.12e+25 (Medium); superclue_reasoning: 4.01e+25 (Medium); superclue_code: 4.81e+25 (Medium); superclue_agents: 4.27e+25 (Medium) → weighted average: 4.27e+25 FLOP),https://www.supercluebench.com/leaderboard (SuperCLUE - Comprehensive Chinese language understanding benchmark),,2025-08-04T16:03:15.514626,,capped
sora_i2v,Unknown,,,,9.9e+24,low,Distant benchmark interpolation or single source,benchmark_based,,not_sure,Threshold-based (physics_iq_score): 10.0 < sora (10.0) → scaled estimate 9.90e+24 FLOP (α=2.0),https://physics-iq.github.io/ (Physics-IQ - Benchmark for physical understanding in video generation models),,2025-08-04T16:03:15.513763,,allowed
doubao_lite_32k,ByteDance,,,,,speculative,Speculative confidence from manual research method,manual_research,,not_sure,,https://github.com/openai/open-agent-leaderboard (Open Agent Leaderboard - Multi-task agent performance evaluation),,2025-08-04T14:10:04.589866,,allowed
doubao_lite_4k,ByteDance,,,,,speculative,Speculative confidence from manual research method,manual_research,,not_sure,,https://gair-nlp.github.io/OlympicArena (OlympicArena - Chinese LLM benchmark across STEM subjects),,2025-08-04T14:10:03.915468,,allowed
doubao_pro_128k,ByteDance,,,,,speculative,Speculative confidence from manual research method,manual_research,,not_sure,,https://github.com/openai/open-agent-leaderboard (Open Agent Leaderboard - Multi-task agent performance evaluation),,2025-08-04T14:10:04.589912,,allowed
doubao_pro_32k,ByteDance,,,,,speculative,Speculative confidence from manual research method,manual_research,,not_sure,,https://gair-nlp.github.io/OlympicArena (OlympicArena - Chinese LLM benchmark across STEM subjects),,2025-08-04T14:10:03.915417,,allowed
gemini_1.0_pro,Google,,,,,speculative,Speculative confidence from manual research method,manual_research,,,,https://gair-nlp.github.io/OlympicArena (OlympicArena - Chinese LLM benchmark across STEM subjects),,2025-08-15T18:13:22.130067,,allowed
hunyuan_standard_vision,Tencent,,,,,speculative,Speculative confidence from manual research method,manual_research,,,,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:24.629522,,allowed
pangu_ultra,Unknown,,,,,speculative,Speculative confidence from manual research method,manual_research,,not_sure,,https://gair-nlp.github.io/OlympicArena (OlympicArena - Chinese LLM benchmark across STEM subjects),,2025-08-04T14:10:03.915579,,allowed
qwen_vl_max,Alibaba,,,,,speculative,Speculative confidence from manual research method,manual_research,,,,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:24.629282,,allowed
step_1o_vision_32k,StepFun,,,,,speculative,Speculative confidence from manual research method,manual_research,,,,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:24.629212,,allowed
step_1v_32k,StepFun,,,,,speculative,Speculative confidence from manual research method,manual_research,,,,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:24.629328,,allowed
yi_large_turbo,01 AI,,,,,speculative,Speculative confidence from manual research method,manual_research,,not_sure,,https://llmbench.github.io/ChineseSimpleQA/ (ChineseSimpleQA - Question answering benchmark for Chinese LLMs),,2025-08-04T14:10:03.623272,,allowed
yi_vision,01 AI,,,,,speculative,Speculative confidence from manual research method,manual_research,,,,https://openlm.ai/chatbot-arena/ (OpenLM Chatbot Arena leaderboard),,2025-08-15T18:13:24.629590,,allowed
